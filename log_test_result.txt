2016-11-27 11:59:18,149 - INFO - Training Begins
2016-11-27 11:59:50,526 - DEBUG - Epoch:     1;  cost=2.333469391
2016-11-27 11:59:50,573 - DEBUG - Accuracy(training batch):0.27344
2016-11-27 12:00:00,490 - INFO - Accuracy - Full Training:nan
2016-11-27 12:00:02,909 - INFO - Accuracy - Full Validation:nan
2016-11-27 12:00:30,569 - DEBUG - Epoch:     2;  cost=1.727293015
2016-11-27 12:00:30,605 - DEBUG - Accuracy(training batch):0.42188
2016-11-27 12:01:00,320 - DEBUG - Epoch:     3;  cost=1.478715777
2016-11-27 12:01:00,358 - DEBUG - Accuracy(training batch):0.49219
2016-11-27 12:01:30,051 - DEBUG - Epoch:     4;  cost=1.079595208
2016-11-27 12:01:30,098 - DEBUG - Accuracy(training batch):0.58594
2016-11-27 12:02:00,303 - DEBUG - Epoch:     5;  cost=0.659602225
2016-11-27 12:02:00,340 - DEBUG - Accuracy(training batch):0.78906
2016-11-27 12:02:30,098 - DEBUG - Epoch:     6;  cost=0.371176511
2016-11-27 12:02:30,147 - DEBUG - Accuracy(training batch):0.87500
2016-11-27 12:03:01,063 - DEBUG - Epoch:     7;  cost=0.283016086
2016-11-27 12:03:01,103 - DEBUG - Accuracy(training batch):0.89844
2016-11-27 12:03:28,895 - DEBUG - Epoch:     8;  cost=0.244554698
2016-11-27 12:03:28,930 - DEBUG - Accuracy(training batch):0.92969
2016-11-27 12:03:58,550 - DEBUG - Epoch:     9;  cost=0.222434521
2016-11-27 12:03:58,585 - DEBUG - Accuracy(training batch):0.92969
2016-11-27 12:04:28,471 - DEBUG - Epoch:    10;  cost=0.162693650
2016-11-27 12:04:28,507 - DEBUG - Accuracy(training batch):0.96094
2016-11-27 12:04:59,297 - DEBUG - Epoch:    11;  cost=0.110810429
2016-11-27 12:04:59,334 - DEBUG - Accuracy(training batch):0.96094
2016-11-27 12:05:31,686 - DEBUG - Epoch:    12;  cost=0.065345220
2016-11-27 12:05:31,729 - DEBUG - Accuracy(training batch):0.97656
2016-11-27 12:06:03,637 - DEBUG - Epoch:    13;  cost=0.088245869
2016-11-27 12:06:03,684 - DEBUG - Accuracy(training batch):0.95312
2016-11-27 12:06:35,420 - DEBUG - Epoch:    14;  cost=0.074400507
2016-11-27 12:06:35,461 - DEBUG - Accuracy(training batch):0.96875
2016-11-27 12:07:06,546 - DEBUG - Epoch:    15;  cost=0.048954312
2016-11-27 12:07:06,587 - DEBUG - Accuracy(training batch):0.98438
2016-11-27 12:07:37,914 - DEBUG - Epoch:    16;  cost=0.080887593
2016-11-27 12:07:37,955 - DEBUG - Accuracy(training batch):0.97656
2016-11-27 12:08:10,934 - DEBUG - Epoch:    17;  cost=0.013827713
2016-11-27 12:08:10,982 - DEBUG - Accuracy(training batch):1.00000
2016-11-27 12:08:42,404 - DEBUG - Epoch:    18;  cost=0.025801931
2016-11-27 12:08:42,440 - DEBUG - Accuracy(training batch):0.98438
2016-11-27 12:09:12,563 - DEBUG - Epoch:    19;  cost=0.032091029
2016-11-27 12:09:12,598 - DEBUG - Accuracy(training batch):0.99219
2016-11-27 12:09:43,931 - DEBUG - Epoch:    20;  cost=0.008807890
2016-11-27 12:09:43,967 - DEBUG - Accuracy(training batch):1.00000
2016-11-27 12:09:44,004 - INFO - Optimization Finished!
2016-11-27 12:09:54,177 - INFO - Accuracy - Full Training:nan
2016-11-27 12:09:57,054 - INFO - Accuracy - Full Validation:nan
2016-11-27 13:42:57,759 - INFO - Training Begins
2016-11-27 13:43:17,614 - DEBUG - Epoch:     1;  cost=2.070500612
2016-11-27 13:43:17,665 - DEBUG - Accuracy(training batch):0.28000
2016-11-27 13:43:23,955 - INFO - Accuracy - Full Training:0.33175
2016-11-27 13:43:25,551 - INFO - Accuracy - Full Validation:0.34107
2016-11-27 13:43:44,625 - DEBUG - Epoch:     2;  cost=1.525725961
2016-11-27 13:43:44,644 - DEBUG - Accuracy(training batch):0.42000
2016-11-27 13:44:05,719 - DEBUG - Epoch:     3;  cost=1.321659565
2016-11-27 13:44:05,741 - DEBUG - Accuracy(training batch):0.52000
2016-11-27 13:44:25,024 - DEBUG - Epoch:     4;  cost=1.107135653
2016-11-27 13:44:25,043 - DEBUG - Accuracy(training batch):0.60000
2016-11-27 13:44:44,060 - DEBUG - Epoch:     5;  cost=0.665615976
2016-11-27 13:44:44,080 - DEBUG - Accuracy(training batch):0.77000
2016-11-27 13:45:03,405 - DEBUG - Epoch:     6;  cost=0.416043997
2016-11-27 13:45:03,429 - DEBUG - Accuracy(training batch):0.87000
2016-11-27 13:45:24,202 - DEBUG - Epoch:     7;  cost=0.356515884
2016-11-27 13:45:24,221 - DEBUG - Accuracy(training batch):0.91000
2016-11-27 13:45:43,563 - DEBUG - Epoch:     8;  cost=0.285426289
2016-11-27 13:45:43,583 - DEBUG - Accuracy(training batch):0.92000
2016-11-27 13:46:03,070 - DEBUG - Epoch:     9;  cost=0.171980247
2016-11-27 13:46:03,089 - DEBUG - Accuracy(training batch):0.95000
2016-11-27 13:46:22,958 - DEBUG - Epoch:    10;  cost=0.144125372
2016-11-27 13:46:22,983 - DEBUG - Accuracy(training batch):0.94000
2016-11-27 13:46:43,790 - DEBUG - Epoch:    11;  cost=0.072607413
2016-11-27 13:46:43,809 - DEBUG - Accuracy(training batch):0.98000
2016-11-27 13:47:03,531 - DEBUG - Epoch:    12;  cost=0.029833343
2016-11-27 13:47:03,556 - DEBUG - Accuracy(training batch):0.99000
2016-11-27 13:47:23,305 - DEBUG - Epoch:    13;  cost=0.029328194
2016-11-27 13:47:23,324 - DEBUG - Accuracy(training batch):0.99000
2016-11-27 13:47:43,645 - DEBUG - Epoch:    14;  cost=0.020713976
2016-11-27 13:47:43,666 - DEBUG - Accuracy(training batch):0.99000
2016-11-27 13:48:04,716 - DEBUG - Epoch:    15;  cost=0.015288215
2016-11-27 13:48:04,736 - DEBUG - Accuracy(training batch):1.00000
2016-11-27 13:48:24,762 - DEBUG - Epoch:    16;  cost=0.064370662
2016-11-27 13:48:24,781 - DEBUG - Accuracy(training batch):0.98000
2016-11-27 13:48:44,757 - DEBUG - Epoch:    17;  cost=0.041201886
2016-11-27 13:48:44,776 - DEBUG - Accuracy(training batch):0.98000
2016-11-27 13:49:05,767 - DEBUG - Epoch:    18;  cost=0.064674795
2016-11-27 13:49:05,791 - DEBUG - Accuracy(training batch):0.98000
2016-11-27 13:49:26,499 - DEBUG - Epoch:    19;  cost=0.004719233
2016-11-27 13:49:26,525 - DEBUG - Accuracy(training batch):1.00000
2016-11-27 13:49:46,494 - DEBUG - Epoch:    20;  cost=0.070795499
2016-11-27 13:49:46,513 - DEBUG - Accuracy(training batch):0.97000
2016-11-27 13:49:46,513 - INFO - Optimization Finished!
2016-11-27 13:49:52,636 - INFO - Accuracy - Full Training:0.99094
2016-11-27 13:49:54,214 - INFO - Accuracy - Full Validation:0.97526
2016-11-27 13:51:16,938 - INFO - Training Begins - GradientDescentOptimizer
2016-11-27 13:51:38,348 - DEBUG - Epoch:     1;  cost=3.757446289
2016-11-27 13:51:38,376 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:51:44,793 - INFO - Accuracy - Full Training:0.06024
2016-11-27 13:51:46,415 - INFO - Accuracy - Full Validation:0.05900
2016-11-27 13:52:05,922 - DEBUG - Epoch:     2;  cost=3.753748417
2016-11-27 13:52:05,942 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:52:25,030 - DEBUG - Epoch:     3;  cost=3.750106812
2016-11-27 13:52:25,049 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:52:44,338 - DEBUG - Epoch:     4;  cost=3.746521711
2016-11-27 13:52:44,361 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:53:04,437 - DEBUG - Epoch:     5;  cost=3.742992163
2016-11-27 13:53:04,456 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:53:26,155 - DEBUG - Epoch:     6;  cost=3.739517450
2016-11-27 13:53:26,181 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:53:50,199 - DEBUG - Epoch:     7;  cost=3.736096859
2016-11-27 13:53:50,219 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:54:11,955 - DEBUG - Epoch:     8;  cost=3.732729435
2016-11-27 13:54:11,975 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:54:31,794 - DEBUG - Epoch:     9;  cost=3.729415178
2016-11-27 13:54:31,815 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:54:53,002 - DEBUG - Epoch:    10;  cost=3.726153612
2016-11-27 13:54:53,035 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:55:13,720 - DEBUG - Epoch:    11;  cost=3.722943068
2016-11-27 13:55:13,745 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:55:35,605 - DEBUG - Epoch:    12;  cost=3.719784260
2016-11-27 13:55:35,624 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:55:58,502 - DEBUG - Epoch:    13;  cost=3.716675520
2016-11-27 13:55:58,522 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:56:19,752 - DEBUG - Epoch:    14;  cost=3.713616371
2016-11-27 13:56:19,796 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:56:44,310 - DEBUG - Epoch:    15;  cost=3.710607052
2016-11-27 13:56:44,332 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:57:04,394 - DEBUG - Epoch:    16;  cost=3.707645893
2016-11-27 13:57:04,420 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:57:24,559 - DEBUG - Epoch:    17;  cost=3.704732418
2016-11-27 13:57:24,578 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:57:44,932 - DEBUG - Epoch:    18;  cost=3.701866388
2016-11-27 13:57:44,958 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:58:06,436 - DEBUG - Epoch:    19;  cost=3.699047327
2016-11-27 13:58:06,456 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:58:26,366 - DEBUG - Epoch:    20;  cost=3.696274042
2016-11-27 13:58:26,391 - DEBUG - Accuracy(training batch):0.09000
2016-11-27 13:58:26,391 - INFO - Optimization Finished!
2016-11-27 13:58:32,810 - INFO - Accuracy - Full Training:0.06024
2016-11-27 13:58:34,456 - INFO - Accuracy - Full Validation:0.05900
2016-11-27 14:05:18,079 - ERROR - Internal Python error in the inspect module.
Below is the traceback from this internal error.

2016-11-27 14:05:18,106 - INFO - 
Unfortunately, your original traceback can not be constructed.

2016-11-27 14:10:21,068 - INFO - Training Begins - AdamOptimizer
2016-11-27 14:10:46,009 - DEBUG - Epoch:     1;  cost=2.307490826
2016-11-27 14:10:46,037 - DEBUG - Accuracy(training batch): 29.00%
2016-11-27 14:10:52,450 - INFO - Accuracy - Full Training:31.67
2016-11-27 14:10:54,094 - INFO - Accuracy - Full Validation:32.07
2016-11-27 14:11:15,129 - DEBUG - Epoch:     2;  cost=1.542129517
2016-11-27 14:11:15,152 - DEBUG - Accuracy(training batch): 43.00%
2016-11-27 14:11:35,533 - DEBUG - Epoch:     3;  cost=1.373928189
2016-11-27 14:11:35,554 - DEBUG - Accuracy(training batch): 56.00%
2016-11-27 14:11:55,533 - DEBUG - Epoch:     4;  cost=1.199510217
2016-11-27 14:11:55,555 - DEBUG - Accuracy(training batch): 61.00%
2016-11-27 14:12:15,120 - DEBUG - Epoch:     5;  cost=0.790062726
2016-11-27 14:12:15,140 - DEBUG - Accuracy(training batch): 72.00%
2016-11-27 14:12:35,158 - DEBUG - Epoch:     6;  cost=0.521227479
2016-11-27 14:12:35,183 - DEBUG - Accuracy(training batch): 84.00%
2016-11-27 14:12:55,422 - DEBUG - Epoch:     7;  cost=0.286977887
2016-11-27 14:12:55,442 - DEBUG - Accuracy(training batch): 93.00%
2016-11-27 14:13:18,555 - DEBUG - Epoch:     8;  cost=0.252250791
2016-11-27 14:13:18,577 - DEBUG - Accuracy(training batch): 94.00%
2016-11-27 14:13:39,284 - DEBUG - Epoch:     9;  cost=0.196296334
2016-11-27 14:13:39,304 - DEBUG - Accuracy(training batch): 93.00%
2016-11-27 14:14:00,497 - DEBUG - Epoch:    10;  cost=0.189157188
2016-11-27 14:14:00,517 - DEBUG - Accuracy(training batch): 93.00%
2016-11-27 14:14:22,336 - DEBUG - Epoch:    11;  cost=0.191283658
2016-11-27 14:14:22,355 - DEBUG - Accuracy(training batch): 96.00%
2016-11-27 14:14:43,541 - DEBUG - Epoch:    12;  cost=0.143634096
2016-11-27 14:14:43,564 - DEBUG - Accuracy(training batch): 95.00%
2016-11-27 14:15:06,712 - DEBUG - Epoch:    13;  cost=0.106221773
2016-11-27 14:15:06,732 - DEBUG - Accuracy(training batch): 98.00%
2016-11-27 14:15:27,417 - DEBUG - Epoch:    14;  cost=0.110270843
2016-11-27 14:15:27,437 - DEBUG - Accuracy(training batch): 96.00%
2016-11-27 14:15:48,597 - DEBUG - Epoch:    15;  cost=0.068233922
2016-11-27 14:15:48,630 - DEBUG - Accuracy(training batch): 97.00%
2016-11-27 14:16:11,429 - DEBUG - Epoch:    16;  cost=0.025576951
2016-11-27 14:16:11,455 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 14:16:33,612 - DEBUG - Epoch:    17;  cost=0.036316983
2016-11-27 14:16:33,636 - DEBUG - Accuracy(training batch): 99.00%
2016-11-27 14:16:54,695 - DEBUG - Epoch:    18;  cost=0.013920587
2016-11-27 14:16:54,723 - DEBUG - Accuracy(training batch): 99.00%
2016-11-27 14:17:16,239 - DEBUG - Epoch:    19;  cost=0.017777147
2016-11-27 14:17:16,269 - DEBUG - Accuracy(training batch): 99.00%
2016-11-27 14:17:39,781 - DEBUG - Epoch:    20;  cost=0.026073165
2016-11-27 14:17:39,802 - DEBUG - Accuracy(training batch): 98.00%
2016-11-27 14:17:39,802 - INFO - Optimization Finished!
2016-11-27 14:17:46,757 - INFO - Accuracy - Full Training:99.08
2016-11-27 14:17:48,492 - INFO - Accuracy - Full Validation:97.38
2016-11-27 14:29:47,881 - INFO - Time usage: 0:07:27
2016-11-27 14:31:01,057 - INFO - Training Begins - AdamOptimizer
2016-11-27 14:31:25,152 - INFO - Training Begins - AdamOptimizer - no pool at the first ConvNet
2016-11-27 14:31:44,691 - DEBUG - Epoch:     1;  cost=2.105852604
2016-11-27 14:31:44,724 - DEBUG - Accuracy(training batch): 29.00%
2016-11-27 14:31:50,908 - INFO - Accuracy - Full Training: 34.32%
2016-11-27 14:31:52,551 - INFO - Accuracy - Full Validation: 35.04%
2016-11-27 14:32:10,001 - DEBUG - Epoch:     2;  cost=1.401328921
2016-11-27 14:32:10,020 - DEBUG - Accuracy(training batch): 52.00%
2016-11-27 14:32:28,029 - DEBUG - Epoch:     3;  cost=0.931073070
2016-11-27 14:32:28,048 - DEBUG - Accuracy(training batch): 67.00%
2016-11-27 14:32:46,724 - DEBUG - Epoch:     4;  cost=0.406501323
2016-11-27 14:32:46,742 - DEBUG - Accuracy(training batch): 90.00%
2016-11-27 14:33:04,985 - DEBUG - Epoch:     5;  cost=0.216798529
2016-11-27 14:33:05,004 - DEBUG - Accuracy(training batch): 92.00%
2016-11-27 14:33:23,073 - DEBUG - Epoch:     6;  cost=0.154305592
2016-11-27 14:33:23,092 - DEBUG - Accuracy(training batch): 96.00%
2016-11-27 14:33:41,261 - DEBUG - Epoch:     7;  cost=0.045131344
2016-11-27 14:33:41,280 - DEBUG - Accuracy(training batch): 99.00%
2016-11-27 14:34:01,081 - DEBUG - Epoch:     8;  cost=0.036377020
2016-11-27 14:34:01,101 - DEBUG - Accuracy(training batch): 99.00%
2016-11-27 14:34:19,794 - DEBUG - Epoch:     9;  cost=0.022129202
2016-11-27 14:34:19,813 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 14:34:38,216 - DEBUG - Epoch:    10;  cost=0.016402047
2016-11-27 14:34:38,235 - DEBUG - Accuracy(training batch): 99.00%
2016-11-27 14:34:58,921 - DEBUG - Epoch:    11;  cost=0.081238844
2016-11-27 14:34:58,940 - DEBUG - Accuracy(training batch): 97.00%
2016-11-27 14:35:17,696 - DEBUG - Epoch:    12;  cost=0.036215659
2016-11-27 14:35:17,715 - DEBUG - Accuracy(training batch): 98.00%
2016-11-27 14:35:36,546 - DEBUG - Epoch:    13;  cost=0.004311120
2016-11-27 14:35:36,565 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 14:35:55,330 - DEBUG - Epoch:    14;  cost=0.003434789
2016-11-27 14:35:55,350 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 14:36:14,894 - DEBUG - Epoch:    15;  cost=0.016329059
2016-11-27 14:36:14,920 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 14:36:37,335 - DEBUG - Epoch:    16;  cost=0.002023319
2016-11-27 14:36:37,354 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 14:36:56,719 - DEBUG - Epoch:    17;  cost=0.029234042
2016-11-27 14:36:56,739 - DEBUG - Accuracy(training batch): 99.00%
2016-11-27 14:37:16,376 - DEBUG - Epoch:    18;  cost=0.009654955
2016-11-27 14:37:16,395 - DEBUG - Accuracy(training batch): 99.00%
2016-11-27 14:37:35,850 - DEBUG - Epoch:    19;  cost=0.011532084
2016-11-27 14:37:35,869 - DEBUG - Accuracy(training batch): 99.00%
2016-11-27 14:37:54,920 - DEBUG - Epoch:    20;  cost=0.024504965
2016-11-27 14:37:54,938 - DEBUG - Accuracy(training batch): 99.00%
2016-11-27 14:37:54,939 - INFO - Optimization Finished!
2016-11-27 14:38:00,971 - INFO - Accuracy - Full Training: 99.66%
2016-11-27 14:38:02,502 - INFO - Accuracy - Full Validation: 98.25%
2016-11-27 14:38:02,503 - INFO - Time usage: 0:06:37
2016-11-27 14:50:25,466 - INFO - Training Begins - AdamOptimizer - no pool at the first ConvNet
2016-11-27 14:50:25,466 - INFO - Learning Rate: 0.001
2016-11-27 14:50:25,467 - INFO - Batch Size: 100
2016-11-27 14:50:25,468 - INFO - Optimizer: name: "Adam_8"
op: "NoOp"
input: "^Adam_8/update_Variable_52/ApplyAdam"
input: "^Adam_8/update_Variable_53/ApplyAdam"
input: "^Adam_8/update_Variable_54/ApplyAdam"
input: "^Adam_8/update_Variable_55/ApplyAdam"
input: "^Adam_8/update_Variable_56/ApplyAdam"
input: "^Adam_8/update_Variable_57/ApplyAdam"
input: "^Adam_8/update_Variable_58/ApplyAdam"
input: "^Adam_8/update_Variable_59/ApplyAdam"
input: "^Adam_8/Assign"
input: "^Adam_8/Assign_1"

2016-11-27 14:51:02,442 - INFO - Training Begins - AdamOptimizer - no pool at the first ConvNet
2016-11-27 14:51:02,443 - INFO - Learning Rate: 0.001
2016-11-27 14:51:02,443 - INFO - Batch Size: 100
2016-11-27 14:51:02,444 - INFO - Optimizer: name: "Adam_8"
op: "NoOp"
input: "^Adam_8/update_Variable_52/ApplyAdam"
input: "^Adam_8/update_Variable_53/ApplyAdam"
input: "^Adam_8/update_Variable_54/ApplyAdam"
input: "^Adam_8/update_Variable_55/ApplyAdam"
input: "^Adam_8/update_Variable_56/ApplyAdam"
input: "^Adam_8/update_Variable_57/ApplyAdam"
input: "^Adam_8/update_Variable_58/ApplyAdam"
input: "^Adam_8/update_Variable_59/ApplyAdam"
input: "^Adam_8/Assign"
input: "^Adam_8/Assign_1"

2016-11-27 14:52:51,737 - INFO - Training Begins - AdamOptimizer - no pool at the first ConvNet
2016-11-27 14:52:51,739 - INFO - Learning Rate: 0.001
2016-11-27 14:52:51,740 - INFO - Batch Size: 100
2016-11-27 14:52:51,741 - INFO - Optimizer: name: "Adam_8"
op: "NoOp"
input: "^Adam_8/update_Variable_52/ApplyAdam"
input: "^Adam_8/update_Variable_53/ApplyAdam"
input: "^Adam_8/update_Variable_54/ApplyAdam"
input: "^Adam_8/update_Variable_55/ApplyAdam"
input: "^Adam_8/update_Variable_56/ApplyAdam"
input: "^Adam_8/update_Variable_57/ApplyAdam"
input: "^Adam_8/update_Variable_58/ApplyAdam"
input: "^Adam_8/update_Variable_59/ApplyAdam"
input: "^Adam_8/Assign"
input: "^Adam_8/Assign_1"

2016-11-27 14:53:24,798 - INFO - Training Begins - AdamOptimizer - no pool at the first ConvNet
2016-11-27 14:53:24,799 - INFO - Learning Rate: 0.001
2016-11-27 14:53:24,800 - INFO - Batch Size: 100
2016-11-27 14:53:24,801 - INFO - Optimizer: name: "Adam_8"
op: "NoOp"
input: "^Adam_8/update_Variable_52/ApplyAdam"
input: "^Adam_8/update_Variable_53/ApplyAdam"
input: "^Adam_8/update_Variable_54/ApplyAdam"
input: "^Adam_8/update_Variable_55/ApplyAdam"
input: "^Adam_8/update_Variable_56/ApplyAdam"
input: "^Adam_8/update_Variable_57/ApplyAdam"
input: "^Adam_8/update_Variable_58/ApplyAdam"
input: "^Adam_8/update_Variable_59/ApplyAdam"
input: "^Adam_8/Assign"
input: "^Adam_8/Assign_1"

2016-11-27 14:54:01,234 - INFO - Training Begins - AdamOptimizer - no pool at the first ConvNet
2016-11-27 14:54:01,236 - INFO - Learning Rate: 0.001
2016-11-27 14:54:01,236 - INFO - Batch Size: 100
2016-11-27 14:54:01,237 - INFO - Optimizer: name: "Adam_8"
op: "NoOp"
input: "^Adam_8/update_Variable_52/ApplyAdam"
input: "^Adam_8/update_Variable_53/ApplyAdam"
input: "^Adam_8/update_Variable_54/ApplyAdam"
input: "^Adam_8/update_Variable_55/ApplyAdam"
input: "^Adam_8/update_Variable_56/ApplyAdam"
input: "^Adam_8/update_Variable_57/ApplyAdam"
input: "^Adam_8/update_Variable_58/ApplyAdam"
input: "^Adam_8/update_Variable_59/ApplyAdam"
input: "^Adam_8/Assign"
input: "^Adam_8/Assign_1"

2016-11-27 15:00:52,016 - INFO - Training Begins - AdamOptimizer - no pool at the first ConvNet
2016-11-27 15:00:52,017 - INFO - Learning Rate: 0.001
2016-11-27 15:00:52,017 - INFO - Batch Size: 100
2016-11-27 15:00:52,018 - INFO - Learning Rate: 0.001
2016-11-27 15:00:52,019 - INFO - layer_convn1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:01:17,602 - INFO - Training Begins - AdamOptimizer - no pool at the first ConvNet
2016-11-27 15:01:17,602 - INFO - Learning Rate: 0.001
2016-11-27 15:01:17,603 - INFO - Batch Size: 100
2016-11-27 15:01:17,603 - INFO - Learning Rate: 0.001
2016-11-27 15:01:17,603 - INFO - layer_convn1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:01:17,604 - INFO - layer_convn2: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:01:17,604 - INFO - layer_fc1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:01:17,604 - INFO - logits: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:01:40,997 - INFO - ===========================
Training Begins - AdamOptimizer - no pool at the first ConvNet
2016-11-27 15:01:40,998 - INFO - Learning Rate: 0.001
2016-11-27 15:01:40,999 - INFO - Batch Size: 100
2016-11-27 15:01:41,000 - INFO - Learning Rate: 0.001
2016-11-27 15:01:41,000 - INFO - layer_convn1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:01:41,000 - INFO - layer_convn2: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:01:41,001 - INFO - layer_fc1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:01:41,001 - INFO - logits: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:07,120 - INFO - ===========================
Training Begins - AdamOptimizer  
==================
2016-11-27 15:02:07,120 - INFO - Learning Rate: 0.001
2016-11-27 15:02:07,120 - INFO - Batch Size: 100
2016-11-27 15:02:07,121 - INFO - Learning Rate: 0.001
2016-11-27 15:02:07,121 - INFO - layer_convn1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:07,121 - INFO - layer_convn2: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:07,122 - INFO - layer_fc1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:07,122 - INFO - logits: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:23,720 - INFO - ===========================
Training Begins - AdamOptimizer  
========================================
2016-11-27 15:02:23,720 - INFO - Learning Rate: 0.001
2016-11-27 15:02:23,721 - INFO - Batch Size: 100
2016-11-27 15:02:23,721 - INFO - Learning Rate: 0.001
2016-11-27 15:02:23,721 - INFO - layer_convn1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:23,721 - INFO - layer_convn2: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:23,722 - INFO - layer_fc1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:23,723 - INFO - logits: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:32,432 - INFO - ===========================
               Training Begins - AdamOptimizer  
===================================================
2016-11-27 15:02:32,433 - INFO - Learning Rate: 0.001
2016-11-27 15:02:32,433 - INFO - Batch Size: 100
2016-11-27 15:02:32,434 - INFO - Learning Rate: 0.001
2016-11-27 15:02:32,434 - INFO - layer_convn1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:32,435 - INFO - layer_convn2: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:32,435 - INFO - layer_fc1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:32,435 - INFO - logits: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:39,960 - INFO - ===========================
                                     Training Begins - AdamOptimizer  
===================================================
2016-11-27 15:02:39,961 - INFO - Learning Rate: 0.001
2016-11-27 15:02:39,961 - INFO - Batch Size: 100
2016-11-27 15:02:39,961 - INFO - Learning Rate: 0.001
2016-11-27 15:02:39,962 - INFO - layer_convn1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:39,962 - INFO - layer_convn2: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:39,963 - INFO - layer_fc1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:39,963 - INFO - logits: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:45,568 - INFO - ===========================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 15:02:45,568 - INFO - Learning Rate: 0.001
2016-11-27 15:02:45,569 - INFO - Batch Size: 100
2016-11-27 15:02:45,569 - INFO - Learning Rate: 0.001
2016-11-27 15:02:45,570 - INFO - layer_convn1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:45,570 - INFO - layer_convn2: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:45,570 - INFO - layer_fc1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:45,571 - INFO - logits: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:47,884 - INFO - ===========================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 15:02:47,885 - INFO - Learning Rate: 0.001
2016-11-27 15:02:47,885 - INFO - Batch Size: 100
2016-11-27 15:02:47,885 - INFO - Learning Rate: 0.001
2016-11-27 15:02:47,887 - INFO - layer_convn1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:47,887 - INFO - layer_convn2: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:47,888 - INFO - layer_fc1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:47,888 - INFO - logits: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:54,165 - INFO - ================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 15:02:54,165 - INFO - Learning Rate: 0.001
2016-11-27 15:02:54,166 - INFO - Batch Size: 100
2016-11-27 15:02:54,166 - INFO - Learning Rate: 0.001
2016-11-27 15:02:54,166 - INFO - layer_convn1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:54,167 - INFO - layer_convn2: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:54,167 - INFO - layer_fc1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:54,168 - INFO - logits: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:58,338 - INFO - =====================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 15:02:58,338 - INFO - Learning Rate: 0.001
2016-11-27 15:02:58,338 - INFO - Batch Size: 100
2016-11-27 15:02:58,339 - INFO - Learning Rate: 0.001
2016-11-27 15:02:58,339 - INFO - layer_convn1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:58,339 - INFO - layer_convn2: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:58,340 - INFO - layer_fc1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:02:58,340 - INFO - logits: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:03:01,654 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 15:03:01,654 - INFO - Learning Rate: 0.001
2016-11-27 15:03:01,655 - INFO - Batch Size: 100
2016-11-27 15:03:01,655 - INFO - Learning Rate: 0.001
2016-11-27 15:03:01,655 - INFO - layer_convn1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:03:01,655 - INFO - layer_convn2: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:03:01,656 - INFO - layer_fc1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:03:01,656 - INFO - logits: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:05:59,356 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 15:05:59,357 - INFO - Learning Rate: 0.001
2016-11-27 15:05:59,357 - INFO - Batch Size: 100
2016-11-27 15:05:59,357 - INFO - Kernal Size: 5 x 5
2016-11-27 15:05:59,357 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 15:05:59,358 - INFO - Learning Rate: 0.001
2016-11-27 15:05:59,358 - INFO - layer_convn1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:05:59,358 - INFO - layer_convn2: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:05:59,359 - INFO - layer_fc1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:05:59,359 - INFO - logits: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:07:03,322 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 15:07:03,323 - INFO - Learning Rate: 0.0001
2016-11-27 15:07:03,323 - INFO - Batch Size: 100
2016-11-27 15:07:03,324 - INFO - Kernal Size: 5 x 5
2016-11-27 15:07:03,324 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 15:07:03,325 - INFO - layer_convn1: Tensor("Relu_21:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:07:03,325 - INFO - layer_convn2: Tensor("Relu_21:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:07:03,326 - INFO - layer_fc1: Tensor("Relu_21:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:07:03,326 - INFO - logits: Tensor("Relu_21:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:07:23,318 - DEBUG - Epoch:     1;  cost=3.541651726
2016-11-27 15:07:23,357 - DEBUG - Accuracy(training batch): 5.00%
2016-11-27 15:07:29,523 - INFO - ***Accuracy - Full Training:       5.16%
2016-11-27 15:07:31,115 - INFO - ***Accuracy - Full Validation:       5.27%
2016-11-27 15:07:48,452 - DEBUG - Epoch:     2;  cost=3.514196873
2016-11-27 15:07:48,472 - DEBUG - Accuracy(training batch): 5.00%
2016-11-27 15:08:06,079 - DEBUG - Epoch:     3;  cost=3.290594578
2016-11-27 15:08:06,099 - DEBUG - Accuracy(training batch): 15.00%
2016-11-27 15:08:23,432 - DEBUG - Epoch:     4;  cost=2.354758501
2016-11-27 15:08:23,451 - DEBUG - Accuracy(training batch): 24.00%
2016-11-27 15:08:40,696 - DEBUG - Epoch:     5;  cost=2.080152512
2016-11-27 15:08:40,715 - DEBUG - Accuracy(training batch): 36.00%
2016-11-27 15:08:58,859 - DEBUG - Epoch:     6;  cost=1.941978097
2016-11-27 15:08:58,878 - DEBUG - Accuracy(training batch): 42.00%
2016-11-27 15:09:16,114 - DEBUG - Epoch:     7;  cost=1.836625338
2016-11-27 15:09:16,132 - DEBUG - Accuracy(training batch): 41.00%
2016-11-27 15:09:33,873 - DEBUG - Epoch:     8;  cost=1.735201716
2016-11-27 15:09:33,892 - DEBUG - Accuracy(training batch): 43.00%
2016-11-27 15:09:51,537 - DEBUG - Epoch:     9;  cost=1.647466898
2016-11-27 15:09:51,556 - DEBUG - Accuracy(training batch): 47.00%
2016-11-27 15:10:09,681 - DEBUG - Epoch:    10;  cost=1.570447087
2016-11-27 15:10:09,702 - DEBUG - Accuracy(training batch): 53.00%
2016-11-27 15:10:27,204 - DEBUG - Epoch:    11;  cost=1.507112980
2016-11-27 15:10:27,223 - DEBUG - Accuracy(training batch): 53.00%
2016-11-27 15:10:44,700 - DEBUG - Epoch:    12;  cost=1.451485038
2016-11-27 15:10:44,724 - DEBUG - Accuracy(training batch): 53.00%
2016-11-27 15:11:02,308 - DEBUG - Epoch:    13;  cost=1.411975503
2016-11-27 15:11:02,327 - DEBUG - Accuracy(training batch): 57.00%
2016-11-27 15:11:19,935 - DEBUG - Epoch:    14;  cost=1.367476463
2016-11-27 15:11:19,954 - DEBUG - Accuracy(training batch): 55.00%
2016-11-27 15:11:37,515 - DEBUG - Epoch:    15;  cost=1.328722477
2016-11-27 15:11:37,535 - DEBUG - Accuracy(training batch): 56.00%
2016-11-27 15:11:55,072 - DEBUG - Epoch:    16;  cost=1.287948608
2016-11-27 15:11:55,091 - DEBUG - Accuracy(training batch): 57.00%
2016-11-27 15:12:12,610 - DEBUG - Epoch:    17;  cost=1.246698141
2016-11-27 15:12:12,628 - DEBUG - Accuracy(training batch): 58.00%
2016-11-27 15:12:30,239 - DEBUG - Epoch:    18;  cost=1.194474459
2016-11-27 15:12:30,258 - DEBUG - Accuracy(training batch): 60.00%
2016-11-27 15:12:47,772 - DEBUG - Epoch:    19;  cost=1.150175214
2016-11-27 15:12:47,790 - DEBUG - Accuracy(training batch): 61.00%
2016-11-27 15:13:05,456 - DEBUG - Epoch:    20;  cost=1.106765032
2016-11-27 15:13:05,475 - DEBUG - Accuracy(training batch): 62.00%
2016-11-27 15:13:05,475 - INFO - Optimization Finished!
2016-11-27 15:13:11,665 - INFO - ***Accuracy - Full Training:       61.17%
2016-11-27 15:13:13,246 - INFO - ***Accuracy - Full Validation:       60.50%
2016-11-27 15:13:13,247 - INFO - Time usage: 0:06:09
2016-11-27 15:14:12,410 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 15:14:12,410 - INFO - Learning Rate: 0.01
2016-11-27 15:14:12,411 - INFO - Batch Size: 100
2016-11-27 15:14:12,411 - INFO - Kernal Size: 5 x 5
2016-11-27 15:14:12,412 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 15:14:12,412 - INFO - layer_convn1: Tensor("Relu_24:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:14:12,413 - INFO - layer_convn2: Tensor("Relu_24:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:14:12,413 - INFO - layer_fc1: Tensor("Relu_24:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:14:12,413 - INFO - logits: Tensor("Relu_24:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:14:31,422 - DEBUG - Epoch:     1;  cost=3.563101530
2016-11-27 15:14:31,454 - DEBUG - Accuracy(training batch): 3.00%
2016-11-27 15:14:37,482 - INFO - ***Accuracy - Full Training:       5.56%
2016-11-27 15:14:39,058 - INFO - ***Accuracy - Full Validation:       5.92%
2016-11-27 15:14:56,403 - DEBUG - Epoch:     2;  cost=3.562325716
2016-11-27 15:14:56,422 - DEBUG - Accuracy(training batch): 3.00%
2016-11-27 15:15:14,421 - DEBUG - Epoch:     3;  cost=3.562185764
2016-11-27 15:15:14,440 - DEBUG - Accuracy(training batch): 3.00%
2016-11-27 15:15:32,294 - DEBUG - Epoch:     4;  cost=3.561096430
2016-11-27 15:15:32,313 - DEBUG - Accuracy(training batch): 3.00%
2016-11-27 15:15:50,134 - DEBUG - Epoch:     5;  cost=3.560094595
2016-11-27 15:15:50,217 - DEBUG - Accuracy(training batch): 3.00%
2016-11-27 15:16:08,110 - DEBUG - Epoch:     6;  cost=3.558801174
2016-11-27 15:16:08,129 - DEBUG - Accuracy(training batch): 3.00%
2016-11-27 15:16:25,929 - DEBUG - Epoch:     7;  cost=3.558464289
2016-11-27 15:16:25,948 - DEBUG - Accuracy(training batch): 3.00%
2016-11-27 15:16:45,234 - DEBUG - Epoch:     8;  cost=3.558238029
2016-11-27 15:16:45,268 - DEBUG - Accuracy(training batch): 3.00%
2016-11-27 15:17:05,774 - DEBUG - Epoch:     9;  cost=3.558106661
2016-11-27 15:17:05,794 - DEBUG - Accuracy(training batch): 3.00%
2016-11-27 15:17:24,408 - DEBUG - Epoch:    10;  cost=3.558058262
2016-11-27 15:17:24,428 - DEBUG - Accuracy(training batch): 3.00%
2016-11-27 15:17:24,428 - INFO - Optimization Finished!
2016-11-27 15:17:30,972 - INFO - ***Accuracy - Full Training:       5.56%
2016-11-27 15:17:32,567 - INFO - ***Accuracy - Full Validation:       5.92%
2016-11-27 15:17:32,567 - INFO - Time usage: 0:03:19
2016-11-27 15:17:40,909 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 15:17:40,910 - INFO - Learning Rate: 0.001
2016-11-27 15:17:40,910 - INFO - Batch Size: 100
2016-11-27 15:17:40,911 - INFO - Kernal Size: 5 x 5
2016-11-27 15:17:40,911 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 15:17:40,911 - INFO - layer_convn1: Tensor("Relu_27:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:17:40,912 - INFO - layer_convn2: Tensor("Relu_27:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:17:40,912 - INFO - layer_fc1: Tensor("Relu_27:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:17:40,913 - INFO - logits: Tensor("Relu_27:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:18:00,699 - DEBUG - Epoch:     1;  cost=2.070258379
2016-11-27 15:18:00,730 - DEBUG - Accuracy(training batch): 28.00%
2016-11-27 15:18:06,769 - INFO - ***Accuracy - Full Training:       33.96%
2016-11-27 15:18:08,339 - INFO - ***Accuracy - Full Validation:       34.31%
2016-11-27 15:18:25,786 - DEBUG - Epoch:     2;  cost=1.420644641
2016-11-27 15:18:25,805 - DEBUG - Accuracy(training batch): 44.00%
2016-11-27 15:18:43,659 - DEBUG - Epoch:     3;  cost=1.120141506
2016-11-27 15:18:43,679 - DEBUG - Accuracy(training batch): 58.00%
2016-11-27 15:19:01,491 - DEBUG - Epoch:     4;  cost=0.720103979
2016-11-27 15:19:01,510 - DEBUG - Accuracy(training batch): 77.00%
2016-11-27 15:19:19,378 - DEBUG - Epoch:     5;  cost=0.339391708
2016-11-27 15:19:19,397 - DEBUG - Accuracy(training batch): 89.00%
2016-11-27 15:19:37,224 - DEBUG - Epoch:     6;  cost=0.226161659
2016-11-27 15:19:37,243 - DEBUG - Accuracy(training batch): 93.00%
2016-11-27 15:19:56,133 - DEBUG - Epoch:     7;  cost=0.055179391
2016-11-27 15:19:56,157 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 15:20:15,003 - DEBUG - Epoch:     8;  cost=0.032707028
2016-11-27 15:20:15,022 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 15:20:36,586 - DEBUG - Epoch:     9;  cost=0.020549979
2016-11-27 15:20:36,611 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 15:20:58,847 - DEBUG - Epoch:    10;  cost=0.008044925
2016-11-27 15:20:58,872 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 15:20:58,873 - INFO - Optimization Finished!
2016-11-27 15:21:05,736 - INFO - ***Accuracy - Full Training:       98.95%
2016-11-27 15:21:07,527 - INFO - ***Accuracy - Full Validation:       97.54%
2016-11-27 15:21:07,528 - INFO - Time usage: 0:03:26
2016-11-27 15:28:14,888 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 15:28:14,888 - INFO - Learning Rate: 0.005
2016-11-27 15:28:14,889 - INFO - Batch Size: 100
2016-11-27 15:28:14,889 - INFO - Kernal Size: 5 x 5
2016-11-27 15:28:14,890 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 15:28:14,891 - INFO - layer_convn1: Tensor("Relu_30:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:28:14,891 - INFO - layer_convn2: Tensor("Relu_30:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:28:14,891 - INFO - layer_fc1: Tensor("Relu_30:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:28:14,892 - INFO - logits: Tensor("Relu_30:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:28:35,202 - DEBUG - Epoch:     1;  cost=1.861460567
2016-11-27 15:28:35,238 - DEBUG - Accuracy(training batch): 42.00%
2016-11-27 15:28:42,090 - INFO - ***Accuracy - Full Training:       42.81%
2016-11-27 15:28:43,736 - INFO - ***Accuracy - Full Validation:       42.89%
2016-11-27 15:29:06,545 - DEBUG - Epoch:     2;  cost=1.204211593
2016-11-27 15:29:06,579 - DEBUG - Accuracy(training batch): 58.00%
2016-11-27 15:29:33,827 - DEBUG - Epoch:     3;  cost=0.908797920
2016-11-27 15:29:33,849 - DEBUG - Accuracy(training batch): 71.00%
2016-11-27 15:29:57,771 - DEBUG - Epoch:     4;  cost=0.811299920
2016-11-27 15:29:57,795 - DEBUG - Accuracy(training batch): 77.00%
2016-11-27 15:30:24,496 - DEBUG - Epoch:     5;  cost=0.713264465
2016-11-27 15:30:24,521 - DEBUG - Accuracy(training batch): 80.00%
2016-11-27 15:30:49,631 - DEBUG - Epoch:     6;  cost=0.718704045
2016-11-27 15:30:49,659 - DEBUG - Accuracy(training batch): 76.00%
2016-11-27 15:31:15,806 - DEBUG - Epoch:     7;  cost=0.665424824
2016-11-27 15:31:15,854 - DEBUG - Accuracy(training batch): 79.00%
2016-11-27 15:31:41,467 - DEBUG - Epoch:     8;  cost=0.625370920
2016-11-27 15:31:41,498 - DEBUG - Accuracy(training batch): 76.00%
2016-11-27 15:32:06,661 - DEBUG - Epoch:     9;  cost=0.600080550
2016-11-27 15:32:06,690 - DEBUG - Accuracy(training batch): 74.00%
2016-11-27 15:32:30,473 - DEBUG - Epoch:    10;  cost=0.618321836
2016-11-27 15:32:30,493 - DEBUG - Accuracy(training batch): 79.00%
2016-11-27 15:32:30,493 - INFO - Optimization Finished!
2016-11-27 15:32:39,394 - INFO - ***Accuracy - Full Training:       81.07%
2016-11-27 15:32:41,706 - INFO - ***Accuracy - Full Validation:       78.87%
2016-11-27 15:32:41,708 - INFO - Time usage: 0:04:26
2016-11-27 15:37:20,296 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 15:37:20,297 - INFO - Learning Rate: 0.0005
2016-11-27 15:37:20,297 - INFO - Batch Size: 100
2016-11-27 15:37:20,298 - INFO - Kernal Size: 5 x 5
2016-11-27 15:37:20,299 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 15:37:20,299 - INFO - layer_convn1: Tensor("Relu_33:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:37:20,300 - INFO - layer_convn2: Tensor("Relu_33:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:37:20,301 - INFO - layer_fc1: Tensor("Relu_33:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:37:20,301 - INFO - logits: Tensor("Relu_33:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:37:39,712 - DEBUG - Epoch:     1;  cost=2.900842190
2016-11-27 15:37:39,748 - DEBUG - Accuracy(training batch): 21.00%
2016-11-27 15:37:45,846 - INFO - ***Accuracy - Full Training:       23.36%
2016-11-27 15:37:47,455 - INFO - ***Accuracy - Full Validation:       24.19%
2016-11-27 15:38:05,229 - DEBUG - Epoch:     2;  cost=1.874091744
2016-11-27 15:38:05,248 - DEBUG - Accuracy(training batch): 35.00%
2016-11-27 15:38:23,338 - DEBUG - Epoch:     3;  cost=1.490451694
2016-11-27 15:38:23,357 - DEBUG - Accuracy(training batch): 53.00%
2016-11-27 15:38:42,930 - DEBUG - Epoch:     4;  cost=1.215439439
2016-11-27 15:38:42,949 - DEBUG - Accuracy(training batch): 58.00%
2016-11-27 15:39:01,018 - DEBUG - Epoch:     5;  cost=1.038076043
2016-11-27 15:39:01,037 - DEBUG - Accuracy(training batch): 64.00%
2016-11-27 15:39:18,953 - DEBUG - Epoch:     6;  cost=0.798429728
2016-11-27 15:39:18,973 - DEBUG - Accuracy(training batch): 73.00%
2016-11-27 15:39:36,656 - DEBUG - Epoch:     7;  cost=0.523898005
2016-11-27 15:39:36,676 - DEBUG - Accuracy(training batch): 80.00%
2016-11-27 15:39:54,581 - DEBUG - Epoch:     8;  cost=0.336898029
2016-11-27 15:39:54,600 - DEBUG - Accuracy(training batch): 88.00%
2016-11-27 15:40:15,392 - DEBUG - Epoch:     9;  cost=0.195129529
2016-11-27 15:40:15,411 - DEBUG - Accuracy(training batch): 96.00%
2016-11-27 15:40:33,678 - DEBUG - Epoch:    10;  cost=0.098629646
2016-11-27 15:40:33,702 - DEBUG - Accuracy(training batch): 98.00%
2016-11-27 15:40:33,702 - INFO - Optimization Finished!
2016-11-27 15:40:39,837 - INFO - ***Accuracy - Full Training:       95.86%
2016-11-27 15:40:41,474 - INFO - ***Accuracy - Full Validation:       94.34%
2016-11-27 15:40:41,475 - INFO - Time usage: 0:03:21
2016-11-27 15:42:47,874 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 15:42:47,874 - INFO - Learning Rate: 0.001
2016-11-27 15:42:47,875 - INFO - Batch Size: 64
2016-11-27 15:42:47,878 - INFO - Kernal Size: 5 x 5
2016-11-27 15:42:47,880 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 15:42:47,881 - INFO - layer_convn1: Tensor("Relu_36:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:42:47,881 - INFO - layer_convn2: Tensor("Relu_36:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:42:47,882 - INFO - layer_fc1: Tensor("Relu_36:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:42:47,884 - INFO - logits: Tensor("Relu_36:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:43:07,957 - DEBUG - Epoch:     1;  cost=1.775526047
2016-11-27 15:43:07,987 - DEBUG - Accuracy(training batch): 35.94%
2016-11-27 15:43:14,280 - INFO - ***Accuracy - Full Training:         38.38%
2016-11-27 15:43:15,937 - INFO - ***Accuracy - Full Validation:       38.79%
2016-11-27 15:43:34,624 - DEBUG - Epoch:     2;  cost=1.245484591
2016-11-27 15:43:34,637 - DEBUG - Accuracy(training batch): 56.25%
2016-11-27 15:43:55,701 - DEBUG - Epoch:     3;  cost=0.547480404
2016-11-27 15:43:55,715 - DEBUG - Accuracy(training batch): 76.56%
2016-11-27 15:44:15,925 - DEBUG - Epoch:     4;  cost=0.302978277
2016-11-27 15:44:15,940 - DEBUG - Accuracy(training batch): 92.19%
2016-11-27 15:44:34,866 - DEBUG - Epoch:     5;  cost=0.287136912
2016-11-27 15:44:34,879 - DEBUG - Accuracy(training batch): 89.06%
2016-11-27 15:44:53,745 - DEBUG - Epoch:     6;  cost=0.252767563
2016-11-27 15:44:53,757 - DEBUG - Accuracy(training batch): 90.62%
2016-11-27 15:45:13,146 - DEBUG - Epoch:     7;  cost=0.117735505
2016-11-27 15:45:13,159 - DEBUG - Accuracy(training batch): 93.75%
2016-11-27 15:45:33,105 - DEBUG - Epoch:     8;  cost=0.228521034
2016-11-27 15:45:33,118 - DEBUG - Accuracy(training batch): 92.19%
2016-11-27 15:45:52,395 - DEBUG - Epoch:     9;  cost=0.068188548
2016-11-27 15:45:52,411 - DEBUG - Accuracy(training batch): 96.88%
2016-11-27 15:46:11,761 - DEBUG - Epoch:    10;  cost=0.037653588
2016-11-27 15:46:11,773 - DEBUG - Accuracy(training batch): 96.88%
2016-11-27 15:46:11,773 - INFO - Optimization Finished!
2016-11-27 15:46:18,145 - INFO - ***Accuracy - Full Training:         98.16%
2016-11-27 15:46:19,762 - INFO - ***Accuracy - Full Validation:       96.99%
2016-11-27 15:46:19,763 - INFO - Time usage: 0:03:31
2016-11-27 15:50:54,402 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 15:50:54,403 - INFO - Learning Rate: 0.001
2016-11-27 15:50:54,403 - INFO - Batch Size: 64
2016-11-27 15:50:54,403 - INFO - Kernal Size: 3 x 3
2016-11-27 15:50:54,404 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 15:50:54,404 - INFO - layer_convn1: Tensor("Relu_39:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:50:54,407 - INFO - layer_convn2: Tensor("Relu_39:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:50:54,410 - INFO - layer_fc1: Tensor("Relu_39:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:50:54,411 - INFO - logits: Tensor("Relu_39:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:51:06,772 - DEBUG - Epoch:     1;  cost=2.248030186
2016-11-27 15:51:06,798 - DEBUG - Accuracy(training batch): 26.56%
2016-11-27 15:51:10,287 - INFO - ***Accuracy - Full Training:         33.31%
2016-11-27 15:51:11,278 - INFO - ***Accuracy - Full Validation:       34.38%
2016-11-27 15:51:22,075 - DEBUG - Epoch:     2;  cost=1.815457106
2016-11-27 15:51:22,084 - DEBUG - Accuracy(training batch): 35.94%
2016-11-27 15:51:33,705 - DEBUG - Epoch:     3;  cost=1.649586439
2016-11-27 15:51:33,712 - DEBUG - Accuracy(training batch): 45.31%
2016-11-27 15:51:44,432 - DEBUG - Epoch:     4;  cost=1.680540681
2016-11-27 15:51:44,440 - DEBUG - Accuracy(training batch): 50.00%
2016-11-27 15:51:56,180 - DEBUG - Epoch:     5;  cost=1.510161757
2016-11-27 15:51:56,189 - DEBUG - Accuracy(training batch): 54.69%
2016-11-27 15:52:07,231 - DEBUG - Epoch:     6;  cost=1.370630860
2016-11-27 15:52:07,239 - DEBUG - Accuracy(training batch): 57.81%
2016-11-27 15:52:17,960 - DEBUG - Epoch:     7;  cost=1.200809956
2016-11-27 15:52:17,968 - DEBUG - Accuracy(training batch): 65.62%
2016-11-27 15:52:28,690 - DEBUG - Epoch:     8;  cost=1.051235914
2016-11-27 15:52:28,697 - DEBUG - Accuracy(training batch): 68.75%
2016-11-27 15:52:39,376 - DEBUG - Epoch:     9;  cost=0.879077911
2016-11-27 15:52:39,383 - DEBUG - Accuracy(training batch): 71.88%
2016-11-27 15:52:50,353 - DEBUG - Epoch:    10;  cost=0.670321226
2016-11-27 15:52:50,360 - DEBUG - Accuracy(training batch): 76.56%
2016-11-27 15:52:50,361 - INFO - Optimization Finished!
2016-11-27 15:52:54,864 - INFO - ***Accuracy - Full Training:         81.15%
2016-11-27 15:52:55,860 - INFO - ***Accuracy - Full Validation:       79.02%
2016-11-27 15:52:55,861 - INFO - Time usage: 0:02:01
2016-11-27 15:53:27,229 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 15:53:27,229 - INFO - Learning Rate: 0.001
2016-11-27 15:53:27,230 - INFO - Batch Size: 64
2016-11-27 15:53:27,230 - INFO - Kernal Size: 7 x 7
2016-11-27 15:53:27,230 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 15:53:27,231 - INFO - layer_convn1: Tensor("Relu_42:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:53:27,231 - INFO - layer_convn2: Tensor("Relu_42:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:53:27,231 - INFO - layer_fc1: Tensor("Relu_42:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:53:27,231 - INFO - logits: Tensor("Relu_42:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 15:53:57,309 - DEBUG - Epoch:     1;  cost=1.525359392
2016-11-27 15:53:57,351 - DEBUG - Accuracy(training batch): 51.56%
2016-11-27 15:54:08,555 - INFO - ***Accuracy - Full Training:         48.63%
2016-11-27 15:54:11,542 - INFO - ***Accuracy - Full Validation:       48.95%
2016-11-27 15:54:41,788 - DEBUG - Epoch:     2;  cost=0.531999230
2016-11-27 15:54:41,829 - DEBUG - Accuracy(training batch): 84.38%
2016-11-27 15:55:25,856 - DEBUG - Epoch:     3;  cost=0.262772977
2016-11-27 15:55:25,878 - DEBUG - Accuracy(training batch): 90.62%
2016-11-27 15:55:56,844 - DEBUG - Epoch:     4;  cost=0.194557473
2016-11-27 15:55:56,877 - DEBUG - Accuracy(training batch): 92.19%
2016-11-27 15:56:57,216 - DEBUG - Epoch:     5;  cost=0.039668642
2016-11-27 15:56:57,260 - DEBUG - Accuracy(training batch): 98.44%
2016-11-27 15:57:57,607 - DEBUG - Epoch:     6;  cost=0.019709911
2016-11-27 15:57:57,659 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 15:58:48,937 - DEBUG - Epoch:     7;  cost=0.031276502
2016-11-27 15:58:48,970 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 15:59:39,359 - DEBUG - Epoch:     8;  cost=0.010899957
2016-11-27 15:59:39,399 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 16:00:30,719 - DEBUG - Epoch:     9;  cost=0.072319701
2016-11-27 16:00:30,753 - DEBUG - Accuracy(training batch): 98.44%
2016-11-27 16:01:20,244 - DEBUG - Epoch:    10;  cost=0.017699484
2016-11-27 16:01:20,273 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 16:01:20,274 - INFO - Optimization Finished!
2016-11-27 16:01:37,531 - INFO - ***Accuracy - Full Training:         98.33%
2016-11-27 16:01:42,280 - INFO - ***Accuracy - Full Validation:       96.88%
2016-11-27 16:01:42,281 - INFO - Time usage: 0:08:14
2016-11-27 16:19:00,164 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 16:19:00,219 - INFO - Learning Rate: 0.001
2016-11-27 16:19:00,219 - INFO - Batch Size: 64
2016-11-27 16:19:00,220 - INFO - Kernal Size: 5 x 5
2016-11-27 16:19:00,220 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 16:19:00,220 - INFO - layer_convn1: Tensor("Relu_45:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 16:19:00,221 - INFO - layer_convn2: Tensor("Relu_45:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 16:19:00,223 - INFO - layer_fc1: Tensor("Relu_45:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 16:19:00,224 - INFO - logits: Tensor("Relu_45:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 16:19:39,104 - DEBUG - Epoch:     1;  cost=1.832343817
2016-11-27 16:19:39,156 - DEBUG - Accuracy(training batch): 37.50%
2016-11-27 16:19:49,665 - INFO - ***Accuracy - Full Training:         38.17%
2016-11-27 16:19:52,597 - INFO - ***Accuracy - Full Validation:       38.24%
2016-11-27 16:20:25,608 - DEBUG - Epoch:     2;  cost=1.125159025
2016-11-27 16:20:25,628 - DEBUG - Accuracy(training batch): 60.94%
2016-11-27 16:20:57,058 - DEBUG - Epoch:     3;  cost=0.542190611
2016-11-27 16:20:57,079 - DEBUG - Accuracy(training batch): 81.25%
2016-11-27 16:21:27,842 - DEBUG - Epoch:     4;  cost=0.237587452
2016-11-27 16:21:27,882 - DEBUG - Accuracy(training batch): 90.62%
2016-11-27 16:22:04,266 - DEBUG - Epoch:     5;  cost=0.137332469
2016-11-27 16:22:04,292 - DEBUG - Accuracy(training batch): 93.75%
2016-11-27 16:22:40,739 - DEBUG - Epoch:     6;  cost=0.107416786
2016-11-27 16:22:40,760 - DEBUG - Accuracy(training batch): 96.88%
2016-11-27 16:23:13,677 - DEBUG - Epoch:     7;  cost=0.052359387
2016-11-27 16:23:13,702 - DEBUG - Accuracy(training batch): 98.44%
2016-11-27 16:23:46,569 - DEBUG - Epoch:     8;  cost=0.013539235
2016-11-27 16:23:46,587 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 16:24:18,247 - DEBUG - Epoch:     9;  cost=0.099171698
2016-11-27 16:24:18,264 - DEBUG - Accuracy(training batch): 96.88%
2016-11-27 16:24:50,811 - DEBUG - Epoch:    10;  cost=0.003672989
2016-11-27 16:24:50,834 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 16:24:50,835 - INFO - Optimization Finished!
2016-11-27 16:25:01,961 - INFO - ***Accuracy - Full Training:         98.88%
2016-11-27 16:25:04,734 - INFO - ***Accuracy - Full Validation:       97.42%
2016-11-27 16:25:04,735 - INFO - Time usage: 0:06:04
2016-11-27 16:25:19,323 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 16:25:19,324 - INFO - Learning Rate: 0.001
2016-11-27 16:25:19,325 - INFO - Batch Size: 64
2016-11-27 16:25:19,325 - INFO - Kernal Size: 5 x 5
2016-11-27 16:25:19,326 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 16:25:19,327 - INFO - layer_convn1: Tensor("Relu_45:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 16:25:19,327 - INFO - layer_convn2: Tensor("Relu_46:0", shape=(?, 8, 8, 32), dtype=float32)
2016-11-27 16:25:19,328 - INFO - layer_fc1: Tensor("Relu_47:0", shape=(?, 128), dtype=float32)
2016-11-27 16:25:19,329 - INFO - logits: Tensor("Add_57:0", shape=(?, 43), dtype=float32)
2016-11-27 17:06:43,329 - DEBUG - Epoch:     1;  cost=1.913234711
2016-11-27 17:06:43,477 - DEBUG - Accuracy(training batch): 40.62%
2016-11-27 17:07:18,634 - DEBUG - Epoch:     2;  cost=1.164264441
2016-11-27 17:07:18,665 - DEBUG - Accuracy(training batch): 62.50%
2016-11-27 17:07:52,754 - DEBUG - Epoch:     3;  cost=0.616941214
2016-11-27 17:07:52,791 - DEBUG - Accuracy(training batch): 81.25%
2016-11-27 17:08:28,459 - DEBUG - Epoch:     4;  cost=0.348375112
2016-11-27 17:08:28,615 - DEBUG - Accuracy(training batch): 87.50%
2016-11-27 17:08:58,357 - DEBUG - Epoch:     5;  cost=0.197583169
2016-11-27 17:08:58,949 - DEBUG - Accuracy(training batch): 93.75%
2016-11-27 17:09:39,404 - DEBUG - Epoch:     6;  cost=0.066048458
2016-11-27 17:09:39,790 - DEBUG - Accuracy(training batch): 98.44%
2016-11-27 17:10:07,990 - DEBUG - Epoch:     7;  cost=0.085028827
2016-11-27 17:10:08,660 - DEBUG - Accuracy(training batch): 96.88%
2016-11-27 17:10:46,551 - DEBUG - Epoch:     8;  cost=0.030718971
2016-11-27 17:10:46,709 - DEBUG - Accuracy(training batch): 98.44%
2016-11-27 17:22:09,888 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 17:22:09,888 - INFO - Learning Rate: 0.001
2016-11-27 17:22:09,889 - INFO - Batch Size: 64
2016-11-27 17:22:09,889 - INFO - Kernal Size: 5 x 5
2016-11-27 17:22:09,890 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 17:22:09,891 - INFO - layer_convn1: Tensor("Relu:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 17:22:09,891 - INFO - layer_convn2: Tensor("Relu_1:0", shape=(?, 8, 8, 32), dtype=float32)
2016-11-27 17:22:09,892 - INFO - layer_fc1: Tensor("Relu_2:0", shape=(?, 128), dtype=float32)
2016-11-27 17:22:09,894 - INFO - logits: Tensor("Add_3:0", shape=(?, 43), dtype=float32)
2016-11-27 17:22:28,553 - DEBUG - Epoch:     1;  cost=1.859109282
2016-11-27 17:22:28,568 - DEBUG - Accuracy(training batch): 35.94%
2016-11-27 17:23:01,259 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 17:23:01,260 - INFO - Learning Rate: 0.001
2016-11-27 17:23:01,260 - INFO - Batch Size: 64
2016-11-27 17:23:01,261 - INFO - Kernal Size: 5 x 5
2016-11-27 17:23:01,262 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 17:23:01,263 - INFO - layer_convn1: Tensor("Relu_3:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 17:23:01,264 - INFO - layer_convn2: Tensor("Relu_4:0", shape=(?, 8, 8, 32), dtype=float32)
2016-11-27 17:23:01,265 - INFO - layer_fc1: Tensor("Relu_5:0", shape=(?, 128), dtype=float32)
2016-11-27 17:23:01,265 - INFO - logits: Tensor("Add_7:0", shape=(?, 43), dtype=float32)
2016-11-27 17:23:19,096 - DEBUG - Epoch:     1;  cost=1.877032876
2016-11-27 17:23:19,111 - DEBUG - Accuracy(training batch): 39.06%
2016-11-27 17:23:19,112 - INFO - Optimization Finished!
2016-11-27 17:24:19,177 - DEBUG - Epoch:     1;  cost=1.974295735
2016-11-27 17:24:19,193 - DEBUG - Accuracy(training batch): 34.38%
2016-11-27 17:24:19,193 - INFO - Optimization Finished!
2016-11-27 17:24:25,273 - INFO - ***Accuracy - Full Training:         36.96%
2016-11-27 17:24:26,960 - INFO - ***Accuracy - Full Validation:       nan%
2016-11-27 17:24:29,553 - INFO - ***Accuracy - Full Test:           nan%
2016-11-27 17:24:29,554 - INFO - Time usage: 0:00:32
2016-11-27 17:25:18,539 - DEBUG - Epoch:     1;  cost=1.916242957
2016-11-27 17:25:18,564 - DEBUG - Accuracy(training batch): 35.94%
2016-11-27 17:25:18,564 - INFO - Optimization Finished!
2016-11-27 17:25:25,817 - INFO - ***Accuracy - Full Training:         39.91%
2016-11-27 17:25:27,526 - INFO - ***Accuracy - Full Validation:       nan%
2016-11-27 17:25:30,101 - INFO - ***Accuracy - Full Test:             nan%
2016-11-27 17:25:36,305 - INFO - ***Accuracy - Full Training:         39.64%
2016-11-27 17:25:37,864 - INFO - ***Accuracy - Full Validation:       39.36%
2016-11-27 17:25:37,865 - INFO - Time usage: 0:00:43
2016-11-27 17:29:09,666 - DEBUG - Epoch:     1;  cost=1.765347600
2016-11-27 17:29:09,682 - DEBUG - Accuracy(training batch): 40.62%
2016-11-27 17:29:09,683 - INFO - Optimization Finished!
2016-11-27 17:29:16,061 - INFO - ***Accuracy - Full Training:         38.92%
2016-11-27 17:29:17,665 - INFO - ***Accuracy - Full Validation:       39.52%
2016-11-27 17:29:20,237 - INFO - ***Accuracy - Full Test:             35.20%
2016-11-27 17:29:26,526 - INFO - ***Accuracy - Full Training:         38.63%
2016-11-27 17:29:28,178 - INFO - ***Accuracy - Full Validation:       39.33%
2016-11-27 17:29:28,179 - INFO - Time usage: 0:00:41
2016-11-27 17:30:48,466 - DEBUG - Epoch:     1;  cost=1.779919386
2016-11-27 17:30:48,496 - DEBUG - Accuracy(training batch): 39.06%
2016-11-27 17:30:48,497 - INFO - Optimization Finished!
2016-11-27 17:30:57,531 - INFO - ***Accuracy - Full Training:         39.89%
2016-11-27 17:31:00,047 - INFO - ***Accuracy - Full Validation:       39.82%
2016-11-27 17:31:04,502 - INFO - ***Accuracy - Full Test:             35.69%
2016-11-27 17:34:09,586 - DEBUG - Epoch:     1;  cost=1.934798360
2016-11-27 17:34:09,607 - DEBUG - Accuracy(training batch): 37.50%
2016-11-27 17:34:09,608 - INFO - Optimization Finished!
2016-11-27 17:34:19,165 - INFO - ***Accuracy - Full Training:         38.86%
2016-11-27 17:34:21,688 - INFO - ***Accuracy - Full Validation:       39.15%
2016-11-27 17:34:25,695 - INFO - ***Accuracy - Full Test:             34.81%
2016-11-27 17:36:10,839 - DEBUG - Epoch:     1;  cost=1.855240107
2016-11-27 17:36:10,866 - DEBUG - Accuracy(training batch): 35.94%
2016-11-27 17:36:10,867 - INFO - Optimization Finished!
2016-11-27 17:36:20,930 - INFO - ***Accuracy - Full Training:         39.04%
2016-11-27 17:36:23,541 - INFO - ***Accuracy - Full Validation:       39.61%
2016-11-27 17:36:27,797 - INFO - ***Accuracy - Full Test:             35.60%
2016-11-27 17:36:37,301 - INFO - ...Accuracy - Full Training:         38.92%
2016-11-27 17:36:39,688 - INFO - ...Accuracy - Full Validation:       39.38%
2016-11-27 17:36:39,689 - INFO - Time usage: 0:01:00
2016-11-27 17:38:26,705 - DEBUG - Epoch:     1;  cost=1.856692314
2016-11-27 17:38:26,728 - DEBUG - Accuracy(training batch): 34.38%
2016-11-27 17:38:26,728 - INFO - Optimization Finished!
2016-11-27 17:38:36,745 - INFO - ***Accuracy - Full Training:         37.71%
2016-11-27 17:38:39,265 - INFO - ***Accuracy - Full Validation:       37.49%
2016-11-27 17:38:43,318 - INFO - ***Accuracy - Full Test:             33.67%
2016-11-27 17:38:53,101 - INFO - ...Accuracy - Full Training:         37.71%
2016-11-27 17:38:55,650 - INFO - ...Accuracy - Full Validation:       37.50%
2016-11-27 17:38:55,651 - INFO - Time usage: 0:01:03
2016-11-27 17:39:31,647 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 17:39:31,648 - INFO - Learning Rate: 0.001
2016-11-27 17:39:31,648 - INFO - Batch Size: 64
2016-11-27 17:39:31,648 - INFO - Kernal Size: 5 x 5
2016-11-27 17:39:31,649 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 17:39:31,649 - INFO - layer_convn1: Tensor("Relu_6:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 17:39:31,650 - INFO - layer_convn2: Tensor("Relu_7:0", shape=(?, 8, 8, 32), dtype=float32)
2016-11-27 17:39:31,650 - INFO - layer_fc1: Tensor("Relu_8:0", shape=(?, 128), dtype=float32)
2016-11-27 17:39:31,651 - INFO - logits: Tensor("Add_11:0", shape=(?, 43), dtype=float32)
2016-11-27 17:40:08,428 - DEBUG - Epoch:     1;  cost=1.735083342
2016-11-27 17:40:08,471 - DEBUG - Accuracy(training batch): 42.19%
2016-11-27 17:40:43,551 - DEBUG - Epoch:     2;  cost=1.008350730
2016-11-27 17:40:43,579 - DEBUG - Accuracy(training batch): 67.19%
2016-11-27 17:41:15,660 - DEBUG - Epoch:     3;  cost=0.337848365
2016-11-27 17:41:15,696 - DEBUG - Accuracy(training batch): 87.50%
2016-11-27 17:41:47,801 - DEBUG - Epoch:     4;  cost=0.248190641
2016-11-27 17:41:47,827 - DEBUG - Accuracy(training batch): 92.19%
2016-11-27 17:42:20,414 - DEBUG - Epoch:     5;  cost=0.160642743
2016-11-27 17:42:20,440 - DEBUG - Accuracy(training batch): 95.31%
2016-11-27 17:42:55,357 - DEBUG - Epoch:     6;  cost=0.051092595
2016-11-27 17:42:55,375 - DEBUG - Accuracy(training batch): 96.88%
2016-11-27 17:43:30,101 - DEBUG - Epoch:     7;  cost=0.018098900
2016-11-27 17:43:30,129 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 17:44:04,284 - DEBUG - Epoch:     8;  cost=0.021971969
2016-11-27 17:44:04,307 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 17:44:36,327 - DEBUG - Epoch:     9;  cost=0.026913606
2016-11-27 17:44:36,349 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 17:45:11,879 - DEBUG - Epoch:    10;  cost=0.004821899
2016-11-27 17:45:11,922 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 17:45:11,923 - INFO - Optimization Finished!
2016-11-27 17:45:24,699 - INFO - ***Accuracy - Full Training:         99.07%
2016-11-27 17:45:27,623 - INFO - ***Accuracy - Full Validation:       97.69%
2016-11-27 17:45:32,863 - INFO - ***Accuracy - Full Test:             85.24%
2016-11-27 17:45:32,865 - INFO - Time usage: 0:06:01
2016-11-27 18:00:51,127 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 18:00:51,279 - INFO - Learning Rate: 0.001
2016-11-27 18:00:51,283 - INFO - Batch Size: 64
2016-11-27 18:00:51,284 - INFO - Kernal Size: 5 x 5
2016-11-27 18:00:51,285 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 18:00:51,286 - INFO - layer_convn1: Tensor("Relu_9:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 18:00:51,286 - INFO - layer_convn2: Tensor("Relu_10:0", shape=(?, 8, 8, 32), dtype=float32)
2016-11-27 18:00:51,287 - INFO - layer_fc1: Tensor("Relu_11:0", shape=(?, 128), dtype=float32)
2016-11-27 18:00:51,288 - INFO - logits: Tensor("Add_15:0", shape=(?, 43), dtype=float32)
2016-11-27 18:01:23,169 - DEBUG - Epoch:     1;  cost=1.898839831
2016-11-27 18:01:23,196 - DEBUG - Accuracy(training batch): 35.94%
2016-11-27 18:01:56,989 - DEBUG - Epoch:     2;  cost=1.315003276
2016-11-27 18:01:57,014 - DEBUG - Accuracy(training batch): 56.25%
2016-11-27 18:02:32,034 - DEBUG - Epoch:     3;  cost=0.604647279
2016-11-27 18:02:32,058 - DEBUG - Accuracy(training batch): 79.69%
2016-11-27 18:03:01,674 - DEBUG - Epoch:     4;  cost=0.262982041
2016-11-27 18:03:01,696 - DEBUG - Accuracy(training batch): 90.62%
2016-11-27 18:03:32,814 - DEBUG - Epoch:     5;  cost=0.190425247
2016-11-27 18:03:32,834 - DEBUG - Accuracy(training batch): 93.75%
2016-11-27 18:04:10,640 - DEBUG - Epoch:     6;  cost=0.075281128
2016-11-27 18:04:10,669 - DEBUG - Accuracy(training batch): 96.88%
2016-11-27 18:04:45,992 - DEBUG - Epoch:     7;  cost=0.010818844
2016-11-27 18:04:46,016 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 18:05:19,636 - DEBUG - Epoch:     8;  cost=0.050357997
2016-11-27 18:05:19,667 - DEBUG - Accuracy(training batch): 96.88%
2016-11-27 18:05:51,449 - DEBUG - Epoch:     9;  cost=0.035040982
2016-11-27 18:05:51,480 - DEBUG - Accuracy(training batch): 98.44%
2016-11-27 18:06:23,040 - DEBUG - Epoch:    10;  cost=0.049551785
2016-11-27 18:06:23,063 - DEBUG - Accuracy(training batch): 98.44%
2016-11-27 18:06:23,076 - INFO - Optimization Finished!
2016-11-27 18:06:32,523 - INFO - ***Accuracy - Full Training:         97.91%
2016-11-27 18:06:34,946 - INFO - ***Accuracy - Full Validation:       96.67%
2016-11-27 18:06:39,417 - INFO - ***Accuracy - Full Test:             84.49%
2016-11-27 18:06:39,419 - INFO - Time usage: 0:05:48
2016-11-27 18:12:38,266 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 18:12:38,361 - INFO - Learning Rate: 0.001
2016-11-27 18:12:38,363 - INFO - Batch Size: 64
2016-11-27 18:12:38,364 - INFO - Kernal Size: 5 x 5
2016-11-27 18:12:38,364 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 18:12:38,365 - INFO - layer_convn1: Tensor("Relu:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 18:12:38,366 - INFO - layer_convn2: Tensor("Relu_1:0", shape=(?, 8, 8, 32), dtype=float32)
2016-11-27 18:12:38,366 - INFO - layer_fc1: Tensor("Relu_2:0", shape=(?, 128), dtype=float32)
2016-11-27 18:12:38,366 - INFO - logits: Tensor("Add_3:0", shape=(?, 43), dtype=float32)
2016-11-27 18:27:13,783 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 18:27:13,783 - INFO - Learning Rate: 0.001
2016-11-27 18:27:13,784 - INFO - Batch Size: 64
2016-11-27 18:27:13,786 - INFO - Kernal Size: 5 x 5
2016-11-27 18:27:13,786 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 18:27:13,787 - INFO - layer_convn1: Tensor("Relu:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 18:27:13,787 - INFO - layer_convn2: Tensor("Relu_1:0", shape=(?, 8, 8, 32), dtype=float32)
2016-11-27 18:27:13,788 - INFO - layer_fc1: Tensor("Relu_2:0", shape=(?, 128), dtype=float32)
2016-11-27 18:27:13,789 - INFO - logits: Tensor("Add_3:0", shape=(?, 43), dtype=float32)
2016-11-27 18:35:58,418 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 18:35:58,418 - INFO - Learning Rate: 0.001
2016-11-27 18:35:58,418 - INFO - Batch Size: 64
2016-11-27 18:35:58,419 - INFO - Kernal Size: 5 x 5
2016-11-27 18:35:58,419 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 18:35:58,420 - INFO - layer_convn1: Tensor("Relu_3:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 18:35:58,422 - INFO - layer_convn2: Tensor("Relu_4:0", shape=(?, 8, 8, 32), dtype=float32)
2016-11-27 18:35:58,422 - INFO - layer_fc1: Tensor("Relu_5:0", shape=(?, 128), dtype=float32)
2016-11-27 18:35:58,423 - INFO - logits: Tensor("Add_7:0", shape=(?, 43), dtype=float32)
2016-11-27 18:36:52,399 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 18:36:52,399 - INFO - Learning Rate: 0.001
2016-11-27 18:36:52,400 - INFO - Batch Size: 64
2016-11-27 18:36:52,402 - INFO - Kernal Size: 5 x 5
2016-11-27 18:36:52,406 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 18:36:52,407 - INFO - layer_convn1: Tensor("Relu_6:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 18:36:52,407 - INFO - layer_convn2: Tensor("Relu_7:0", shape=(?, 8, 8, 32), dtype=float32)
2016-11-27 18:36:52,408 - INFO - layer_fc1: Tensor("Relu_8:0", shape=(?, 128), dtype=float32)
2016-11-27 18:36:52,409 - INFO - logits: Tensor("Add_11:0", shape=(?, 43), dtype=float32)
2016-11-27 18:44:18,379 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 18:44:18,380 - INFO - Learning Rate: 0.001
2016-11-27 18:44:18,381 - INFO - Batch Size: 64
2016-11-27 18:44:18,381 - INFO - Kernal Size: 5 x 5
2016-11-27 18:44:18,382 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 18:44:18,431 - INFO - layer_convn1: Tensor("Relu_9:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 18:44:18,432 - INFO - layer_convn2: Tensor("Relu_10:0", shape=(?, 8, 8, 32), dtype=float32)
2016-11-27 18:44:18,432 - INFO - layer_fc1: Tensor("Relu_11:0", shape=(?, 128), dtype=float32)
2016-11-27 18:44:18,432 - INFO - logits: Tensor("Add_15:0", shape=(?, 43), dtype=float32)
2016-11-27 18:44:43,220 - DEBUG - Epoch:     1;  cost=1.808075428
2016-11-27 18:44:43,245 - DEBUG - Accuracy(training batch): 35.94%
2016-11-27 18:45:02,718 - DEBUG - Epoch:     2;  cost=1.030215859
2016-11-27 18:45:02,731 - DEBUG - Accuracy(training batch): 65.62%
2016-11-27 18:45:21,883 - DEBUG - Epoch:     3;  cost=0.524387717
2016-11-27 18:45:21,896 - DEBUG - Accuracy(training batch): 82.81%
2016-11-27 18:45:44,596 - DEBUG - Epoch:     4;  cost=0.373030603
2016-11-27 18:45:44,648 - DEBUG - Accuracy(training batch): 87.50%
2016-11-27 18:46:13,196 - DEBUG - Epoch:     5;  cost=0.237402245
2016-11-27 18:46:13,215 - DEBUG - Accuracy(training batch): 92.19%
2016-11-27 18:46:35,168 - DEBUG - Epoch:     6;  cost=0.131269798
2016-11-27 18:46:35,181 - DEBUG - Accuracy(training batch): 92.19%
2016-11-27 18:46:59,575 - DEBUG - Epoch:     7;  cost=0.033310264
2016-11-27 18:46:59,609 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 18:47:23,084 - DEBUG - Epoch:     8;  cost=0.029541850
2016-11-27 18:47:23,098 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 18:47:45,911 - DEBUG - Epoch:     9;  cost=0.014589068
2016-11-27 18:47:45,931 - DEBUG - Accuracy(training batch): 100.00%
2016-11-27 18:48:09,875 - DEBUG - Epoch:    10;  cost=0.036651030
2016-11-27 18:48:09,888 - DEBUG - Accuracy(training batch): 96.88%
2016-11-27 18:48:09,888 - INFO - Optimization Finished!
2016-11-27 18:48:17,376 - INFO - ***Accuracy - Full Training:         98.88%
2016-11-27 18:48:19,354 - INFO - ***Accuracy - Full Validation:       97.16%
2016-11-27 18:48:22,119 - INFO - ***Accuracy - Full Test:             85.08%
2016-11-27 18:48:22,120 - INFO - Time usage: 0:04:03
2016-11-27 20:50:50,321 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 20:50:50,483 - INFO - Learning Rate: 0.001
2016-11-27 20:50:50,483 - INFO - Batch Size: 64
2016-11-27 20:50:50,484 - INFO - Kernal Size: 5 x 5
2016-11-27 20:50:50,485 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 20:50:50,486 - INFO - layer_convn1: Tensor("Relu_12:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 20:50:50,486 - INFO - layer_convn2: Tensor("Relu_13:0", shape=(?, 8, 8, 32), dtype=float32)
2016-11-27 20:50:50,487 - INFO - layer_fc1: Tensor("Relu_14:0", shape=(?, 128), dtype=float32)
2016-11-27 20:50:50,488 - INFO - logits: Tensor("Add_19:0", shape=(?, 43), dtype=float32)
2016-11-27 20:51:48,393 - DEBUG - Epoch:     1;  cost=1.303295135
2016-11-27 20:51:48,424 - DEBUG - Accuracy(training batch): 51.56%
2016-11-27 20:52:45,010 - DEBUG - Epoch:     2;  cost=0.473269999
2016-11-27 20:52:45,023 - DEBUG - Accuracy(training batch): 81.25%
2016-11-27 20:53:41,935 - DEBUG - Epoch:     3;  cost=0.426274836
2016-11-27 20:53:41,947 - DEBUG - Accuracy(training batch): 84.38%
2016-11-27 20:54:39,132 - DEBUG - Epoch:     4;  cost=0.457318425
2016-11-27 20:54:39,144 - DEBUG - Accuracy(training batch): 84.38%
2016-11-27 20:55:36,877 - DEBUG - Epoch:     5;  cost=0.630749702
2016-11-27 20:55:36,890 - DEBUG - Accuracy(training batch): 90.62%
2016-11-27 20:56:34,941 - DEBUG - Epoch:     6;  cost=0.308379292
2016-11-27 20:56:34,954 - DEBUG - Accuracy(training batch): 89.06%
2016-11-27 20:57:36,985 - DEBUG - Epoch:     7;  cost=0.144185603
2016-11-27 20:57:36,998 - DEBUG - Accuracy(training batch): 95.31%
2016-11-27 20:58:34,629 - DEBUG - Epoch:     8;  cost=0.111294568
2016-11-27 20:58:34,644 - DEBUG - Accuracy(training batch): 95.31%
2016-11-27 20:59:32,348 - DEBUG - Epoch:     9;  cost=0.087119989
2016-11-27 20:59:32,360 - DEBUG - Accuracy(training batch): 95.31%
2016-11-27 21:00:30,154 - DEBUG - Epoch:    10;  cost=0.056862485
2016-11-27 21:00:30,168 - DEBUG - Accuracy(training batch): 98.44%
2016-11-27 21:00:30,168 - INFO - Optimization Finished!
2016-11-27 21:00:48,727 - INFO - ***Accuracy - Full Training:         96.57%
2016-11-27 21:00:53,399 - INFO - ***Accuracy - Full Validation:       94.60%
2016-11-27 21:00:55,931 - INFO - ***Accuracy - Full Test:             78.74%
2016-11-27 21:00:55,932 - INFO - Time usage: 0:10:05
2016-11-27 21:08:31,021 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 21:08:31,021 - INFO - Learning Rate: 0.001
2016-11-27 21:08:31,022 - INFO - Batch Size: 64
2016-11-27 21:08:31,023 - INFO - Kernal Size: 5 x 5
2016-11-27 21:08:31,023 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 21:08:31,023 - INFO - layer_convn1: Tensor("Relu_18:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 21:08:31,023 - INFO - layer_convn2: Tensor("Relu_19:0", shape=(?, 8, 8, 32), dtype=float32)
2016-11-27 21:08:31,024 - INFO - layer_fc1: Tensor("dropout_1/mul:0", shape=(?, 128), dtype=float32)
2016-11-27 21:08:31,024 - INFO - logits: Tensor("Add_26:0", shape=(?, 43), dtype=float32)
2016-11-27 21:23:42,748 - DEBUG - Epoch:     1;  cost=1.315199971
2016-11-27 21:23:42,771 - DEBUG - Accuracy(training batch): 50.00%
2016-11-27 21:24:39,810 - DEBUG - Epoch:     2;  cost=0.565307379
2016-11-27 21:24:39,822 - DEBUG - Accuracy(training batch): 84.38%
2016-11-27 21:25:37,026 - DEBUG - Epoch:     3;  cost=0.514857411
2016-11-27 21:25:37,039 - DEBUG - Accuracy(training batch): 85.94%
2016-11-27 21:26:35,323 - DEBUG - Epoch:     4;  cost=0.381398231
2016-11-27 21:26:35,336 - DEBUG - Accuracy(training batch): 85.94%
2016-11-27 21:27:32,617 - DEBUG - Epoch:     5;  cost=0.239086270
2016-11-27 21:27:32,631 - DEBUG - Accuracy(training batch): 92.19%
2016-11-27 21:28:33,315 - DEBUG - Epoch:     6;  cost=0.363277733
2016-11-27 21:28:33,328 - DEBUG - Accuracy(training batch): 89.06%
2016-11-27 21:29:31,392 - DEBUG - Epoch:     7;  cost=0.272531390
2016-11-27 21:29:31,405 - DEBUG - Accuracy(training batch): 93.75%
2016-11-27 21:30:28,964 - DEBUG - Epoch:     8;  cost=0.313243389
2016-11-27 21:30:28,977 - DEBUG - Accuracy(training batch): 93.75%
2016-11-27 21:31:26,566 - DEBUG - Epoch:     9;  cost=0.250580788
2016-11-27 21:31:26,579 - DEBUG - Accuracy(training batch): 96.88%
2016-11-27 21:32:24,292 - DEBUG - Epoch:    10;  cost=0.071417198
2016-11-27 21:32:24,305 - DEBUG - Accuracy(training batch): 95.31%
2016-11-27 21:32:24,306 - INFO - Optimization Finished!
2016-11-27 21:32:43,093 - INFO - ***Accuracy - Full Training:         93.70%
2016-11-27 21:32:47,824 - INFO - ***Accuracy - Full Validation:       91.93%
2016-11-27 21:32:50,375 - INFO - ***Accuracy - Full Test:             78.83%
2016-11-27 21:32:50,375 - INFO - Time usage: 0:10:11
2016-11-27 21:58:19,703 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 21:58:19,703 - INFO - Learning Rate: 0.001
2016-11-27 21:58:19,704 - INFO - Batch Size: 64
2016-11-27 21:58:19,704 - INFO - Kernal Size: 5 x 5
2016-11-27 21:58:19,705 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 21:58:19,705 - INFO - layer_convn1: Tensor("Relu_24:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 21:58:19,706 - INFO - layer_convn2: Tensor("Relu_25:0", shape=(?, 8, 8, 32), dtype=float32)
2016-11-27 21:58:19,706 - INFO - layer_fc1: Tensor("dropout_3/mul:0", shape=(?, 128), dtype=float32)
2016-11-27 21:58:19,706 - INFO - logits: Tensor("Add_34:0", shape=(?, 43), dtype=float32)
2016-11-27 21:59:18,198 - DEBUG - Epoch:     1;  cost=1.434641361
2016-11-27 21:59:18,222 - DEBUG - Accuracy(training batch): 57.81%
2016-11-27 22:00:16,378 - DEBUG - Epoch:     2;  cost=0.770719647
2016-11-27 22:00:16,391 - DEBUG - Accuracy(training batch): 76.56%
2016-11-27 22:01:14,460 - DEBUG - Epoch:     3;  cost=0.499506772
2016-11-27 22:01:14,475 - DEBUG - Accuracy(training batch): 78.12%
2016-11-27 22:02:12,746 - DEBUG - Epoch:     4;  cost=0.704920053
2016-11-27 22:02:12,760 - DEBUG - Accuracy(training batch): 81.25%
2016-11-27 22:03:11,089 - DEBUG - Epoch:     5;  cost=0.523412108
2016-11-27 22:03:11,109 - DEBUG - Accuracy(training batch): 81.25%
2016-11-27 22:04:13,323 - DEBUG - Epoch:     6;  cost=0.339851707
2016-11-27 22:04:13,336 - DEBUG - Accuracy(training batch): 90.62%
2016-11-27 22:05:11,006 - DEBUG - Epoch:     7;  cost=0.308506966
2016-11-27 22:05:11,019 - DEBUG - Accuracy(training batch): 92.19%
2016-11-27 22:06:08,506 - DEBUG - Epoch:     8;  cost=0.299264014
2016-11-27 22:06:08,519 - DEBUG - Accuracy(training batch): 87.50%
2016-11-27 22:07:05,915 - DEBUG - Epoch:     9;  cost=0.368265688
2016-11-27 22:07:05,929 - DEBUG - Accuracy(training batch): 90.62%
2016-11-27 22:08:03,545 - DEBUG - Epoch:    10;  cost=0.330686569
2016-11-27 22:08:03,558 - DEBUG - Accuracy(training batch): 90.62%
2016-11-27 22:09:01,263 - DEBUG - Epoch:    11;  cost=0.291400015
2016-11-27 22:09:01,275 - DEBUG - Accuracy(training batch): 92.19%
2016-11-27 22:09:59,062 - DEBUG - Epoch:    12;  cost=0.393612057
2016-11-27 22:09:59,074 - DEBUG - Accuracy(training batch): 85.94%
2016-11-27 22:10:56,875 - DEBUG - Epoch:    13;  cost=0.085050561
2016-11-27 22:10:56,889 - DEBUG - Accuracy(training batch): 93.75%
2016-11-27 22:11:54,648 - DEBUG - Epoch:    14;  cost=0.422089577
2016-11-27 22:11:54,661 - DEBUG - Accuracy(training batch): 92.19%
2016-11-27 22:12:52,382 - DEBUG - Epoch:    15;  cost=0.165357038
2016-11-27 22:12:52,395 - DEBUG - Accuracy(training batch): 92.19%
2016-11-27 22:13:50,284 - DEBUG - Epoch:    16;  cost=0.284150451
2016-11-27 22:13:50,297 - DEBUG - Accuracy(training batch): 92.19%
2016-11-27 22:14:48,135 - DEBUG - Epoch:    17;  cost=0.218854457
2016-11-27 22:14:48,148 - DEBUG - Accuracy(training batch): 92.19%
2016-11-27 22:15:46,119 - DEBUG - Epoch:    18;  cost=0.112479538
2016-11-27 22:15:46,131 - DEBUG - Accuracy(training batch): 93.75%
2016-11-27 22:16:44,025 - DEBUG - Epoch:    19;  cost=0.192549691
2016-11-27 22:16:44,039 - DEBUG - Accuracy(training batch): 87.50%
2016-11-27 22:17:43,516 - DEBUG - Epoch:    20;  cost=0.164714739
2016-11-27 22:17:43,529 - DEBUG - Accuracy(training batch): 95.31%
2016-11-27 22:17:43,529 - INFO - Optimization Finished!
2016-11-27 22:18:02,500 - INFO - ***Accuracy - Full Training:         93.48%
2016-11-27 22:18:07,251 - INFO - ***Accuracy - Full Validation:       91.43%
2016-11-27 22:18:09,833 - INFO - ***Accuracy - Full Test:             75.88%
2016-11-27 22:18:09,834 - INFO - Time usage: 0:19:50
2016-11-27 22:21:18,278 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 22:21:18,279 - INFO - Learning Rate: 0.001
2016-11-27 22:21:18,279 - INFO - Batch Size: 64
2016-11-27 22:21:18,279 - INFO - Kernal Size: 5 x 5
2016-11-27 22:21:18,280 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 22:21:36,017 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 22:21:36,017 - INFO - Learning Rate: 0.001
2016-11-27 22:21:36,017 - INFO - Batch Size: 64
2016-11-27 22:21:36,017 - INFO - Kernal Size: 5 x 5
2016-11-27 22:21:36,018 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 22:21:36,018 - INFO - Dropout keep_prob: 0.8
2016-11-27 22:21:36,018 - INFO - layer_convn1: Tensor("Relu_24:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 22:21:36,019 - INFO - layer_convn2: Tensor("Relu_25:0", shape=(?, 8, 8, 32), dtype=float32)
2016-11-27 22:21:36,019 - INFO - layer_fc1: Tensor("dropout_3/mul:0", shape=(?, 128), dtype=float32)
2016-11-27 22:21:36,019 - INFO - logits: Tensor("Add_34:0", shape=(?, 43), dtype=float32)
2016-11-27 23:40:28,867 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-27 23:40:28,867 - INFO - Learning Rate: 0.001
2016-11-27 23:40:28,868 - INFO - Batch Size: 64
2016-11-27 23:40:28,868 - INFO - Kernal Size: 5 x 5
2016-11-27 23:40:28,868 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-27 23:40:28,868 - INFO - Dropout keep_prob: 0.8
2016-11-27 23:40:28,868 - INFO - layer_convn1: Tensor("Relu:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-27 23:40:28,869 - INFO - layer_convn2: Tensor("Relu_1:0", shape=(?, 8, 8, 32), dtype=float32)
2016-11-27 23:40:28,870 - INFO - layer_fc1: Tensor("dropout/mul:0", shape=(?, 128), dtype=float32)
2016-11-27 23:40:28,870 - INFO - logits: Tensor("Add_3:0", shape=(?, 43), dtype=float32)
2016-11-27 23:41:43,310 - DEBUG - Epoch:     1;  cost=1.801616430
2016-11-27 23:41:43,326 - DEBUG - Accuracy(training batch): 40.62%
2016-11-27 23:42:03,332 - INFO - ***Accuracy - Full Training:         48.49%
2016-11-27 23:42:08,260 - INFO - ***Accuracy - Full Validation:       48.66%
2016-11-27 23:42:10,925 - INFO - ***Accuracy - Full Test:             36.13%
2016-11-27 23:43:19,649 - DEBUG - Epoch:     2;  cost=1.072483063
2016-11-27 23:43:19,662 - DEBUG - Accuracy(training batch): 64.06%
2016-11-27 23:43:38,924 - INFO - ***Accuracy - Full Training:         64.29%
2016-11-27 23:43:43,686 - INFO - ***Accuracy - Full Validation:       63.70%
2016-11-27 23:43:46,258 - INFO - ***Accuracy - Full Test:             46.40%
2016-11-27 23:45:26,934 - DEBUG - Epoch:     1;  cost=1.603858590
2016-11-27 23:45:26,949 - DEBUG - Accuracy(training batch): 42.19%
2016-11-27 23:45:46,122 - INFO - ***Accuracy - Full Training:         47.49%
2016-11-27 23:45:50,981 - INFO - ***Accuracy - Full Validation:       47.03%
2016-11-27 23:45:53,549 - INFO - ***Accuracy - Full Test:             38.79%
2016-11-27 23:46:50,082 - DEBUG - Epoch:     2;  cost=1.039314985
2016-11-27 23:46:50,095 - DEBUG - Accuracy(training batch): 57.81%
2016-11-27 23:47:46,870 - DEBUG - Epoch:     3;  cost=0.767637849
2016-11-27 23:47:46,883 - DEBUG - Accuracy(training batch): 84.38%
2016-11-27 23:48:43,693 - DEBUG - Epoch:     4;  cost=0.803421974
2016-11-27 23:48:43,706 - DEBUG - Accuracy(training batch): 73.44%
2016-11-27 23:49:40,635 - DEBUG - Epoch:     5;  cost=0.370649755
2016-11-27 23:49:40,648 - DEBUG - Accuracy(training batch): 92.19%
2016-11-27 23:50:37,603 - DEBUG - Epoch:     6;  cost=0.600750029
2016-11-27 23:50:37,616 - DEBUG - Accuracy(training batch): 85.94%
2016-11-27 23:51:41,398 - DEBUG - Epoch:     7;  cost=0.303838134
2016-11-27 23:51:41,411 - DEBUG - Accuracy(training batch): 85.94%
2016-11-27 23:52:38,024 - DEBUG - Epoch:     8;  cost=0.448161781
2016-11-27 23:52:38,042 - DEBUG - Accuracy(training batch): 85.94%
2016-11-27 23:53:34,837 - DEBUG - Epoch:     9;  cost=0.638906360
2016-11-27 23:53:34,850 - DEBUG - Accuracy(training batch): 82.81%
2016-11-27 23:54:31,677 - DEBUG - Epoch:    10;  cost=0.495234370
2016-11-27 23:54:31,690 - DEBUG - Accuracy(training batch): 87.50%
2016-11-27 23:55:28,574 - DEBUG - Epoch:    11;  cost=0.285601914
2016-11-27 23:55:28,586 - DEBUG - Accuracy(training batch): 87.50%
2016-11-27 23:55:47,025 - INFO - ***Accuracy - Full Training:         88.92%
2016-11-27 23:55:51,684 - INFO - ***Accuracy - Full Validation:       87.21%
2016-11-27 23:55:54,235 - INFO - ***Accuracy - Full Test:             73.99%
2016-11-27 23:56:51,200 - DEBUG - Epoch:    12;  cost=0.174549267
2016-11-27 23:56:51,212 - DEBUG - Accuracy(training batch): 92.19%
2016-11-27 23:57:48,217 - DEBUG - Epoch:    13;  cost=0.472450912
2016-11-27 23:57:48,230 - DEBUG - Accuracy(training batch): 85.94%
2016-11-27 23:58:45,091 - DEBUG - Epoch:    14;  cost=0.259745061
2016-11-27 23:58:45,104 - DEBUG - Accuracy(training batch): 90.62%
2016-11-27 23:59:42,141 - DEBUG - Epoch:    15;  cost=0.153458297
2016-11-27 23:59:42,153 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 00:00:39,266 - DEBUG - Epoch:    16;  cost=0.146040291
2016-11-28 00:00:39,289 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 00:01:36,486 - DEBUG - Epoch:    17;  cost=0.302939385
2016-11-28 00:01:36,499 - DEBUG - Accuracy(training batch): 87.50%
2016-11-28 00:02:33,652 - DEBUG - Epoch:    18;  cost=0.386368275
2016-11-28 00:02:33,665 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 00:03:30,940 - DEBUG - Epoch:    19;  cost=0.209626019
2016-11-28 00:03:30,953 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 00:04:28,212 - DEBUG - Epoch:    20;  cost=0.521109402
2016-11-28 00:04:28,225 - DEBUG - Accuracy(training batch): 87.50%
2016-11-28 00:04:28,225 - INFO - Optimization Finished!
2016-11-28 00:04:46,692 - INFO - ***Accuracy - Full Training:         90.42%
2016-11-28 00:04:51,347 - INFO - ***Accuracy - Full Validation:       88.56%
2016-11-28 00:04:53,885 - INFO - ***Accuracy - Full Test:             78.50%
2016-11-28 00:04:53,886 - INFO - Time usage: 0:24:24
2016-11-28 07:36:26,134 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-28 07:36:26,376 - INFO - Learning Rate: 0.001
2016-11-28 07:36:26,378 - INFO - Batch Size: 64
2016-11-28 07:36:26,378 - INFO - Kernal Size: 5 x 5
2016-11-28 07:36:26,378 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-28 07:36:26,379 - INFO - Dropout keep_prob: 0.8
2016-11-28 07:36:26,379 - INFO - layer_convn1: Tensor("Relu_3:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-28 07:36:26,380 - INFO - layer_convn2: Tensor("Relu_4:0", shape=(?, 8, 8, 32), dtype=float32)
2016-11-28 07:36:26,381 - INFO - layer_fc1: Tensor("dropout_1/mul:0", shape=(?, 128), dtype=float32)
2016-11-28 07:36:26,382 - INFO - logits: Tensor("Add_7:0", shape=(?, 43), dtype=float32)
2016-11-28 07:37:22,650 - DEBUG - Epoch:     1;  cost=1.794802427
2016-11-28 07:37:22,668 - DEBUG - Accuracy(training batch): 45.31%
2016-11-28 07:37:40,814 - INFO - ***Accuracy - Full Training:         47.76%
2016-11-28 07:37:45,441 - INFO - ***Accuracy - Full Validation:       47.31%
2016-11-28 07:37:47,979 - INFO - ***Accuracy - Full Test:             35.87%
2016-11-28 07:38:43,185 - DEBUG - Epoch:     2;  cost=0.938562691
2016-11-28 07:38:43,197 - DEBUG - Accuracy(training batch): 62.50%
2016-11-28 07:39:38,570 - DEBUG - Epoch:     3;  cost=0.848295927
2016-11-28 07:39:38,584 - DEBUG - Accuracy(training batch): 75.00%
2016-11-28 07:40:34,873 - DEBUG - Epoch:     4;  cost=0.589605451
2016-11-28 07:40:34,886 - DEBUG - Accuracy(training batch): 79.69%
2016-11-28 07:41:30,350 - DEBUG - Epoch:     5;  cost=0.628688097
2016-11-28 07:41:30,363 - DEBUG - Accuracy(training batch): 78.12%
2016-11-28 07:42:25,831 - DEBUG - Epoch:     6;  cost=0.566665232
2016-11-28 07:42:25,844 - DEBUG - Accuracy(training batch): 81.25%
2016-11-28 07:43:21,418 - DEBUG - Epoch:     7;  cost=0.502776504
2016-11-28 07:43:21,430 - DEBUG - Accuracy(training batch): 78.12%
2016-11-28 07:44:20,962 - DEBUG - Epoch:     8;  cost=0.577133656
2016-11-28 07:44:20,975 - DEBUG - Accuracy(training batch): 71.88%
2016-11-28 07:45:16,577 - DEBUG - Epoch:     9;  cost=0.421542943
2016-11-28 07:45:16,589 - DEBUG - Accuracy(training batch): 78.12%
2016-11-28 07:46:12,160 - DEBUG - Epoch:    10;  cost=0.609354496
2016-11-28 07:46:12,172 - DEBUG - Accuracy(training batch): 76.56%
2016-11-28 07:47:07,829 - DEBUG - Epoch:    11;  cost=0.486269057
2016-11-28 07:47:07,841 - DEBUG - Accuracy(training batch): 82.81%
2016-11-28 07:47:25,990 - INFO - ***Accuracy - Full Training:         86.53%
2016-11-28 07:47:30,576 - INFO - ***Accuracy - Full Validation:       84.96%
2016-11-28 07:47:33,053 - INFO - ***Accuracy - Full Test:             73.41%
2016-11-28 07:48:28,806 - DEBUG - Epoch:    12;  cost=0.730933368
2016-11-28 07:48:28,818 - DEBUG - Accuracy(training batch): 73.44%
2016-11-28 07:49:24,531 - DEBUG - Epoch:    13;  cost=0.837931991
2016-11-28 07:49:24,544 - DEBUG - Accuracy(training batch): 75.00%
2016-11-28 07:50:20,164 - DEBUG - Epoch:    14;  cost=0.436789095
2016-11-28 07:50:20,190 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 07:51:15,895 - DEBUG - Epoch:    15;  cost=0.736009538
2016-11-28 07:51:15,908 - DEBUG - Accuracy(training batch): 85.94%
2016-11-28 07:52:11,605 - DEBUG - Epoch:    16;  cost=0.440309137
2016-11-28 07:52:11,617 - DEBUG - Accuracy(training batch): 81.25%
2016-11-28 07:53:07,437 - DEBUG - Epoch:    17;  cost=0.408788383
2016-11-28 07:53:07,450 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 07:54:03,161 - DEBUG - Epoch:    18;  cost=0.190010265
2016-11-28 07:54:03,173 - DEBUG - Accuracy(training batch): 87.50%
2016-11-28 07:54:58,934 - DEBUG - Epoch:    19;  cost=0.324082702
2016-11-28 07:54:58,946 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 07:55:55,479 - DEBUG - Epoch:    20;  cost=0.484129131
2016-11-28 07:55:55,497 - DEBUG - Accuracy(training batch): 79.69%
2016-11-28 07:56:54,721 - DEBUG - Epoch:    21;  cost=0.852782726
2016-11-28 07:56:54,734 - DEBUG - Accuracy(training batch): 84.38%
2016-11-28 07:57:12,886 - INFO - ***Accuracy - Full Training:         84.19%
2016-11-28 07:57:17,497 - INFO - ***Accuracy - Full Validation:       82.22%
2016-11-28 07:57:19,987 - INFO - ***Accuracy - Full Test:             75.76%
2016-11-28 07:58:15,814 - DEBUG - Epoch:    22;  cost=0.267096996
2016-11-28 07:58:15,827 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 07:59:11,661 - DEBUG - Epoch:    23;  cost=0.612486243
2016-11-28 07:59:11,673 - DEBUG - Accuracy(training batch): 81.25%
2016-11-28 08:00:07,474 - DEBUG - Epoch:    24;  cost=0.389101326
2016-11-28 08:00:07,487 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 08:01:03,358 - DEBUG - Epoch:    25;  cost=0.291830510
2016-11-28 08:01:03,371 - DEBUG - Accuracy(training batch): 87.50%
2016-11-28 08:01:59,216 - DEBUG - Epoch:    26;  cost=0.280507147
2016-11-28 08:01:59,228 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 08:02:55,233 - DEBUG - Epoch:    27;  cost=0.261922479
2016-11-28 08:02:55,246 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 08:03:51,349 - DEBUG - Epoch:    28;  cost=0.378446281
2016-11-28 08:03:51,362 - DEBUG - Accuracy(training batch): 82.81%
2016-11-28 08:04:47,639 - DEBUG - Epoch:    29;  cost=0.492785811
2016-11-28 08:04:47,652 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 08:05:44,288 - DEBUG - Epoch:    30;  cost=0.333133459
2016-11-28 08:05:44,301 - DEBUG - Accuracy(training batch): 87.50%
2016-11-28 08:06:41,190 - DEBUG - Epoch:    31;  cost=0.176024258
2016-11-28 08:06:41,203 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 08:06:59,420 - INFO - ***Accuracy - Full Training:         90.31%
2016-11-28 08:07:04,013 - INFO - ***Accuracy - Full Validation:       88.00%
2016-11-28 08:07:06,499 - INFO - ***Accuracy - Full Test:             77.41%
2016-11-28 08:08:03,827 - DEBUG - Epoch:    32;  cost=0.289981514
2016-11-28 08:08:03,839 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 08:09:01,479 - DEBUG - Epoch:    33;  cost=0.319554508
2016-11-28 08:09:01,491 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 08:09:59,324 - DEBUG - Epoch:    34;  cost=0.349019170
2016-11-28 08:09:59,337 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 08:10:57,687 - DEBUG - Epoch:    35;  cost=0.316493511
2016-11-28 08:10:57,700 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 08:11:56,125 - DEBUG - Epoch:    36;  cost=0.349554121
2016-11-28 08:11:56,138 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 08:12:54,553 - DEBUG - Epoch:    37;  cost=0.463941038
2016-11-28 08:12:54,565 - DEBUG - Accuracy(training batch): 85.94%
2016-11-28 08:13:52,907 - DEBUG - Epoch:    38;  cost=0.108851090
2016-11-28 08:13:52,919 - DEBUG - Accuracy(training batch): 98.44%
2016-11-28 08:14:51,348 - DEBUG - Epoch:    39;  cost=0.235109150
2016-11-28 08:14:51,360 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 08:15:49,742 - DEBUG - Epoch:    40;  cost=0.187618807
2016-11-28 08:15:49,755 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 08:16:48,144 - DEBUG - Epoch:    41;  cost=0.316615522
2016-11-28 08:16:48,166 - DEBUG - Accuracy(training batch): 85.94%
2016-11-28 08:17:06,399 - INFO - ***Accuracy - Full Training:         89.48%
2016-11-28 08:17:10,981 - INFO - ***Accuracy - Full Validation:       87.60%
2016-11-28 08:17:13,490 - INFO - ***Accuracy - Full Test:             78.45%
2016-11-28 08:18:11,920 - DEBUG - Epoch:    42;  cost=0.187311724
2016-11-28 08:18:11,933 - DEBUG - Accuracy(training batch): 87.50%
2016-11-28 08:19:10,429 - DEBUG - Epoch:    43;  cost=0.311340421
2016-11-28 08:19:10,442 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 08:20:08,904 - DEBUG - Epoch:    44;  cost=0.250300944
2016-11-28 08:20:08,916 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 08:21:07,501 - DEBUG - Epoch:    45;  cost=0.192916363
2016-11-28 08:21:07,513 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 08:22:06,081 - DEBUG - Epoch:    46;  cost=0.290492684
2016-11-28 08:22:06,094 - DEBUG - Accuracy(training batch): 87.50%
2016-11-28 08:23:04,722 - DEBUG - Epoch:    47;  cost=0.292507470
2016-11-28 08:23:04,735 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 08:24:03,218 - DEBUG - Epoch:    48;  cost=0.243424803
2016-11-28 08:24:03,231 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 08:25:01,839 - DEBUG - Epoch:    49;  cost=0.298516124
2016-11-28 08:25:01,851 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 08:26:00,391 - DEBUG - Epoch:    50;  cost=0.140835285
2016-11-28 08:26:00,404 - DEBUG - Accuracy(training batch): 100.00%
2016-11-28 08:26:58,941 - DEBUG - Epoch:    51;  cost=0.292314529
2016-11-28 08:26:58,954 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 08:27:17,106 - INFO - ***Accuracy - Full Training:         90.35%
2016-11-28 08:27:21,702 - INFO - ***Accuracy - Full Validation:       87.95%
2016-11-28 08:27:24,199 - INFO - ***Accuracy - Full Test:             77.92%
2016-11-28 08:28:22,807 - DEBUG - Epoch:    52;  cost=0.169474155
2016-11-28 08:28:22,820 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 08:29:21,455 - DEBUG - Epoch:    53;  cost=0.180296302
2016-11-28 08:29:21,468 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 08:30:20,029 - DEBUG - Epoch:    54;  cost=0.113702998
2016-11-28 08:30:20,044 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 08:31:18,585 - DEBUG - Epoch:    55;  cost=0.372801811
2016-11-28 08:31:18,597 - DEBUG - Accuracy(training batch): 85.94%
2016-11-28 08:32:17,110 - DEBUG - Epoch:    56;  cost=0.231933087
2016-11-28 08:32:17,125 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 08:33:15,705 - DEBUG - Epoch:    57;  cost=0.183048666
2016-11-28 08:33:15,717 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 08:34:14,278 - DEBUG - Epoch:    58;  cost=0.302772433
2016-11-28 08:34:14,291 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 08:35:12,989 - DEBUG - Epoch:    59;  cost=0.352841794
2016-11-28 08:35:13,002 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 08:36:11,650 - DEBUG - Epoch:    60;  cost=0.329568923
2016-11-28 08:36:11,662 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 08:37:10,356 - DEBUG - Epoch:    61;  cost=0.306559384
2016-11-28 08:37:10,369 - DEBUG - Accuracy(training batch): 87.50%
2016-11-28 08:37:28,519 - INFO - ***Accuracy - Full Training:         91.23%
2016-11-28 08:37:33,110 - INFO - ***Accuracy - Full Validation:       88.74%
2016-11-28 08:37:35,598 - INFO - ***Accuracy - Full Test:             79.33%
2016-11-28 08:38:34,113 - DEBUG - Epoch:    62;  cost=0.190069392
2016-11-28 08:38:34,125 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 08:39:32,736 - DEBUG - Epoch:    63;  cost=0.293002516
2016-11-28 08:39:32,749 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 08:40:32,123 - DEBUG - Epoch:    64;  cost=0.140240878
2016-11-28 08:40:32,136 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 08:41:30,948 - DEBUG - Epoch:    65;  cost=0.118899204
2016-11-28 08:41:30,961 - DEBUG - Accuracy(training batch): 85.94%
2016-11-28 08:42:29,517 - DEBUG - Epoch:    66;  cost=0.174262881
2016-11-28 08:42:29,530 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 08:43:28,164 - DEBUG - Epoch:    67;  cost=0.146516442
2016-11-28 08:43:28,177 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 08:44:26,879 - DEBUG - Epoch:    68;  cost=0.229484364
2016-11-28 08:44:26,891 - DEBUG - Accuracy(training batch): 87.50%
2016-11-28 08:45:25,640 - DEBUG - Epoch:    69;  cost=0.149754763
2016-11-28 08:45:25,653 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 08:46:24,339 - DEBUG - Epoch:    70;  cost=0.764435470
2016-11-28 08:46:24,352 - DEBUG - Accuracy(training batch): 82.81%
2016-11-28 08:47:23,085 - DEBUG - Epoch:    71;  cost=0.274631649
2016-11-28 08:47:23,098 - DEBUG - Accuracy(training batch): 98.44%
2016-11-28 08:47:41,248 - INFO - ***Accuracy - Full Training:         92.42%
2016-11-28 08:47:45,894 - INFO - ***Accuracy - Full Validation:       90.33%
2016-11-28 08:47:48,393 - INFO - ***Accuracy - Full Test:             79.38%
2016-11-28 08:48:47,178 - DEBUG - Epoch:    72;  cost=0.181472272
2016-11-28 08:48:47,190 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 08:49:45,827 - DEBUG - Epoch:    73;  cost=0.440882325
2016-11-28 08:49:45,840 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 08:50:44,411 - DEBUG - Epoch:    74;  cost=0.446463704
2016-11-28 08:50:44,424 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 08:51:43,110 - DEBUG - Epoch:    75;  cost=0.268761784
2016-11-28 08:51:43,122 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 08:52:41,695 - DEBUG - Epoch:    76;  cost=0.244360149
2016-11-28 08:52:41,708 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 08:53:40,443 - DEBUG - Epoch:    77;  cost=0.232717082
2016-11-28 08:53:40,455 - DEBUG - Accuracy(training batch): 87.50%
2016-11-28 08:54:39,201 - DEBUG - Epoch:    78;  cost=0.078940600
2016-11-28 08:54:39,214 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 08:55:37,957 - DEBUG - Epoch:    79;  cost=0.656106710
2016-11-28 08:55:37,969 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 08:56:36,678 - DEBUG - Epoch:    80;  cost=0.396091104
2016-11-28 08:56:36,691 - DEBUG - Accuracy(training batch): 84.38%
2016-11-28 08:57:35,466 - DEBUG - Epoch:    81;  cost=0.242053151
2016-11-28 08:57:35,479 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 08:57:53,698 - INFO - ***Accuracy - Full Training:         91.06%
2016-11-28 08:57:58,293 - INFO - ***Accuracy - Full Validation:       88.98%
2016-11-28 08:58:00,783 - INFO - ***Accuracy - Full Test:             79.92%
2016-11-28 08:58:59,636 - DEBUG - Epoch:    82;  cost=0.437226295
2016-11-28 08:58:59,649 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 08:59:58,393 - DEBUG - Epoch:    83;  cost=0.430285752
2016-11-28 08:59:58,408 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 09:00:57,330 - DEBUG - Epoch:    84;  cost=0.244349167
2016-11-28 09:00:57,343 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 09:01:56,208 - DEBUG - Epoch:    85;  cost=0.203224033
2016-11-28 09:01:56,220 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 09:02:55,046 - DEBUG - Epoch:    86;  cost=0.261494279
2016-11-28 09:02:55,058 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 09:03:53,898 - DEBUG - Epoch:    87;  cost=0.145305812
2016-11-28 09:03:53,910 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 09:04:52,750 - DEBUG - Epoch:    88;  cost=0.437761605
2016-11-28 09:04:52,762 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 09:05:51,552 - DEBUG - Epoch:    89;  cost=0.214586586
2016-11-28 09:05:51,565 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 09:06:50,365 - DEBUG - Epoch:    90;  cost=0.446958095
2016-11-28 09:06:50,377 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 09:07:49,465 - DEBUG - Epoch:    91;  cost=0.160109743
2016-11-28 09:07:49,478 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 09:08:07,616 - INFO - ***Accuracy - Full Training:         92.19%
2016-11-28 09:08:12,202 - INFO - ***Accuracy - Full Validation:       90.12%
2016-11-28 09:08:14,695 - INFO - ***Accuracy - Full Test:             79.46%
2016-11-28 09:09:13,601 - DEBUG - Epoch:    92;  cost=0.205657750
2016-11-28 09:09:13,614 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 09:10:12,719 - DEBUG - Epoch:    93;  cost=0.214943856
2016-11-28 09:10:12,732 - DEBUG - Accuracy(training batch): 85.94%
2016-11-28 09:11:11,654 - DEBUG - Epoch:    94;  cost=0.146061122
2016-11-28 09:11:11,667 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 09:12:10,576 - DEBUG - Epoch:    95;  cost=0.265385926
2016-11-28 09:12:10,589 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 09:13:09,557 - DEBUG - Epoch:    96;  cost=0.168684423
2016-11-28 09:13:09,570 - DEBUG - Accuracy(training batch): 98.44%
2016-11-28 09:14:08,469 - DEBUG - Epoch:    97;  cost=0.402902246
2016-11-28 09:14:08,481 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 09:15:07,521 - DEBUG - Epoch:    98;  cost=0.249616921
2016-11-28 09:15:07,533 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 09:16:06,556 - DEBUG - Epoch:    99;  cost=0.200030774
2016-11-28 09:16:06,568 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 09:17:05,646 - DEBUG - Epoch:   100;  cost=0.148409545
2016-11-28 09:17:05,659 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 09:18:04,653 - DEBUG - Epoch:   101;  cost=0.424783230
2016-11-28 09:18:04,665 - DEBUG - Accuracy(training batch): 85.94%
2016-11-28 09:18:22,795 - INFO - ***Accuracy - Full Training:         92.63%
2016-11-28 09:18:27,399 - INFO - ***Accuracy - Full Validation:       90.32%
2016-11-28 09:18:29,887 - INFO - ***Accuracy - Full Test:             79.62%
2016-11-28 09:19:28,994 - DEBUG - Epoch:   102;  cost=0.206570417
2016-11-28 09:19:29,006 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 09:20:28,004 - DEBUG - Epoch:   103;  cost=0.128071681
2016-11-28 09:20:28,016 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 09:21:27,064 - DEBUG - Epoch:   104;  cost=0.148082182
2016-11-28 09:21:27,076 - DEBUG - Accuracy(training batch): 98.44%
2016-11-28 09:22:25,928 - DEBUG - Epoch:   105;  cost=0.218496904
2016-11-28 09:22:25,941 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 09:23:24,980 - DEBUG - Epoch:   106;  cost=0.192628622
2016-11-28 09:23:24,993 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 09:24:24,027 - DEBUG - Epoch:   107;  cost=0.071237385
2016-11-28 09:24:24,044 - DEBUG - Accuracy(training batch): 98.44%
2016-11-28 09:25:23,054 - DEBUG - Epoch:   108;  cost=0.227777809
2016-11-28 09:25:23,067 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 09:26:22,121 - DEBUG - Epoch:   109;  cost=0.370394796
2016-11-28 09:26:22,133 - DEBUG - Accuracy(training batch): 85.94%
2016-11-28 09:27:21,180 - DEBUG - Epoch:   110;  cost=0.166959018
2016-11-28 09:27:21,193 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 09:28:20,326 - DEBUG - Epoch:   111;  cost=0.213772640
2016-11-28 09:28:20,339 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 09:28:38,477 - INFO - ***Accuracy - Full Training:         93.52%
2016-11-28 09:28:43,069 - INFO - ***Accuracy - Full Validation:       91.23%
2016-11-28 09:28:45,562 - INFO - ***Accuracy - Full Test:             80.12%
2016-11-28 09:29:44,703 - DEBUG - Epoch:   112;  cost=0.282532692
2016-11-28 09:29:44,716 - DEBUG - Accuracy(training batch): 85.94%
2016-11-28 09:30:43,749 - DEBUG - Epoch:   113;  cost=0.170123279
2016-11-28 09:30:43,762 - DEBUG - Accuracy(training batch): 87.50%
2016-11-28 09:31:43,044 - DEBUG - Epoch:   114;  cost=0.199596047
2016-11-28 09:31:43,056 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 09:32:42,196 - DEBUG - Epoch:   115;  cost=0.081849203
2016-11-28 09:32:42,208 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 09:33:41,364 - DEBUG - Epoch:   116;  cost=0.167253256
2016-11-28 09:33:41,376 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 09:34:40,526 - DEBUG - Epoch:   117;  cost=0.318088293
2016-11-28 09:34:40,539 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 09:35:39,739 - DEBUG - Epoch:   118;  cost=0.157362014
2016-11-28 09:35:39,751 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 09:36:38,976 - DEBUG - Epoch:   119;  cost=0.340333223
2016-11-28 09:36:38,988 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 09:37:38,275 - DEBUG - Epoch:   120;  cost=0.182477728
2016-11-28 09:37:38,288 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 09:38:37,850 - DEBUG - Epoch:   121;  cost=0.193849415
2016-11-28 09:38:37,862 - DEBUG - Accuracy(training batch): 98.44%
2016-11-28 09:38:56,069 - INFO - ***Accuracy - Full Training:         93.12%
2016-11-28 09:39:00,668 - INFO - ***Accuracy - Full Validation:       90.74%
2016-11-28 09:39:03,156 - INFO - ***Accuracy - Full Test:             79.81%
2016-11-28 09:40:03,187 - DEBUG - Epoch:   122;  cost=0.547924221
2016-11-28 09:40:03,200 - DEBUG - Accuracy(training batch): 85.94%
2016-11-28 09:41:02,571 - DEBUG - Epoch:   123;  cost=0.214135215
2016-11-28 09:41:02,584 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 09:42:01,749 - DEBUG - Epoch:   124;  cost=0.099911287
2016-11-28 09:42:01,762 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 09:43:01,034 - DEBUG - Epoch:   125;  cost=0.154875934
2016-11-28 09:43:01,048 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 09:44:00,179 - DEBUG - Epoch:   126;  cost=0.352603883
2016-11-28 09:44:00,192 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 09:44:59,358 - DEBUG - Epoch:   127;  cost=0.620627463
2016-11-28 09:44:59,370 - DEBUG - Accuracy(training batch): 98.44%
2016-11-28 09:45:58,638 - DEBUG - Epoch:   128;  cost=0.067650273
2016-11-28 09:45:58,650 - DEBUG - Accuracy(training batch): 98.44%
2016-11-28 09:46:57,798 - DEBUG - Epoch:   129;  cost=0.147109792
2016-11-28 09:46:57,810 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 09:47:57,174 - DEBUG - Epoch:   130;  cost=0.054461662
2016-11-28 09:47:57,187 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 09:48:56,390 - DEBUG - Epoch:   131;  cost=0.238941506
2016-11-28 09:48:56,403 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 09:49:14,563 - INFO - ***Accuracy - Full Training:         92.74%
2016-11-28 09:49:19,168 - INFO - ***Accuracy - Full Validation:       90.41%
2016-11-28 09:49:21,654 - INFO - ***Accuracy - Full Test:             80.76%
2016-11-28 09:50:20,938 - DEBUG - Epoch:   132;  cost=0.103634059
2016-11-28 09:50:20,950 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 09:51:20,169 - DEBUG - Epoch:   133;  cost=0.070063174
2016-11-28 09:51:20,182 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 09:52:19,369 - DEBUG - Epoch:   134;  cost=0.328158587
2016-11-28 09:52:19,382 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 09:53:18,778 - DEBUG - Epoch:   135;  cost=0.300362021
2016-11-28 09:53:18,791 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 09:54:18,134 - DEBUG - Epoch:   136;  cost=0.446160406
2016-11-28 09:54:18,146 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 09:55:17,864 - DEBUG - Epoch:   137;  cost=0.091012672
2016-11-28 09:55:17,877 - DEBUG - Accuracy(training batch): 98.44%
2016-11-28 09:56:17,251 - DEBUG - Epoch:   138;  cost=0.192717046
2016-11-28 09:56:17,263 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 09:57:16,615 - DEBUG - Epoch:   139;  cost=0.165595084
2016-11-28 09:57:16,628 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 09:58:16,005 - DEBUG - Epoch:   140;  cost=0.326557040
2016-11-28 09:58:16,018 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 09:59:15,357 - DEBUG - Epoch:   141;  cost=0.175643608
2016-11-28 09:59:15,369 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 09:59:33,514 - INFO - ***Accuracy - Full Training:         91.36%
2016-11-28 09:59:38,112 - INFO - ***Accuracy - Full Validation:       88.91%
2016-11-28 09:59:40,597 - INFO - ***Accuracy - Full Test:             79.37%
2016-11-28 10:00:40,019 - DEBUG - Epoch:   142;  cost=0.278349668
2016-11-28 10:00:40,036 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 10:01:39,406 - DEBUG - Epoch:   143;  cost=0.210358992
2016-11-28 10:01:39,419 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 10:02:38,948 - DEBUG - Epoch:   144;  cost=0.265304655
2016-11-28 10:02:38,960 - DEBUG - Accuracy(training batch): 85.94%
2016-11-28 10:03:38,403 - DEBUG - Epoch:   145;  cost=0.275295436
2016-11-28 10:03:38,417 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 10:04:37,753 - DEBUG - Epoch:   146;  cost=0.186895519
2016-11-28 10:04:37,765 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 10:05:37,253 - DEBUG - Epoch:   147;  cost=0.308020443
2016-11-28 10:05:37,265 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 10:06:36,778 - DEBUG - Epoch:   148;  cost=0.125649989
2016-11-28 10:06:36,791 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 10:07:36,261 - DEBUG - Epoch:   149;  cost=0.228560299
2016-11-28 10:07:36,274 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 10:08:36,019 - DEBUG - Epoch:   150;  cost=0.155604243
2016-11-28 10:08:36,035 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 10:09:35,463 - DEBUG - Epoch:   151;  cost=0.611723900
2016-11-28 10:09:35,475 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 10:09:53,620 - INFO - ***Accuracy - Full Training:         90.77%
2016-11-28 10:09:58,228 - INFO - ***Accuracy - Full Validation:       88.58%
2016-11-28 10:10:00,712 - INFO - ***Accuracy - Full Test:             80.60%
2016-11-28 10:11:00,296 - DEBUG - Epoch:   152;  cost=0.279790729
2016-11-28 10:11:00,309 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 10:11:59,614 - DEBUG - Epoch:   153;  cost=0.082789294
2016-11-28 10:11:59,627 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 10:12:59,270 - DEBUG - Epoch:   154;  cost=0.414429724
2016-11-28 10:12:59,283 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 10:13:58,464 - DEBUG - Epoch:   155;  cost=0.083866015
2016-11-28 10:13:58,476 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 10:14:57,909 - DEBUG - Epoch:   156;  cost=0.144413054
2016-11-28 10:14:57,921 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 10:15:57,329 - DEBUG - Epoch:   157;  cost=0.221528605
2016-11-28 10:15:57,342 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 10:16:56,849 - DEBUG - Epoch:   158;  cost=0.026615364
2016-11-28 10:16:56,862 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 10:17:56,437 - DEBUG - Epoch:   159;  cost=0.293978214
2016-11-28 10:17:56,450 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 10:18:55,944 - DEBUG - Epoch:   160;  cost=0.197905749
2016-11-28 10:18:55,957 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 10:19:55,366 - DEBUG - Epoch:   161;  cost=0.116272882
2016-11-28 10:19:55,379 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 10:20:13,542 - INFO - ***Accuracy - Full Training:         92.97%
2016-11-28 10:20:18,125 - INFO - ***Accuracy - Full Validation:       90.52%
2016-11-28 10:20:20,611 - INFO - ***Accuracy - Full Test:             79.30%
2016-11-28 10:21:20,241 - DEBUG - Epoch:   162;  cost=0.422115833
2016-11-28 10:21:20,254 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 10:22:19,856 - DEBUG - Epoch:   163;  cost=0.234348401
2016-11-28 10:22:19,868 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 10:23:19,651 - DEBUG - Epoch:   164;  cost=0.676319242
2016-11-28 10:23:19,664 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 10:24:19,131 - DEBUG - Epoch:   165;  cost=0.135454267
2016-11-28 10:24:19,144 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 10:25:18,831 - DEBUG - Epoch:   166;  cost=0.612681508
2016-11-28 10:25:18,844 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 10:26:18,375 - DEBUG - Epoch:   167;  cost=0.133804306
2016-11-28 10:26:18,387 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 10:27:18,085 - DEBUG - Epoch:   168;  cost=0.144119024
2016-11-28 10:27:18,098 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 10:28:17,495 - DEBUG - Epoch:   169;  cost=0.381493151
2016-11-28 10:28:17,507 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 10:29:17,014 - DEBUG - Epoch:   170;  cost=0.271868616
2016-11-28 10:29:17,032 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 10:30:16,550 - DEBUG - Epoch:   171;  cost=0.209134489
2016-11-28 10:30:16,563 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 10:30:34,699 - INFO - ***Accuracy - Full Training:         92.08%
2016-11-28 10:30:39,295 - INFO - ***Accuracy - Full Validation:       89.85%
2016-11-28 10:30:41,780 - INFO - ***Accuracy - Full Test:             79.79%
2016-11-28 10:31:41,330 - DEBUG - Epoch:   172;  cost=0.192786068
2016-11-28 10:31:41,343 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 10:32:40,842 - DEBUG - Epoch:   173;  cost=0.683902502
2016-11-28 10:32:40,854 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 10:33:40,414 - DEBUG - Epoch:   174;  cost=0.280005991
2016-11-28 10:33:40,427 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 10:34:40,192 - DEBUG - Epoch:   175;  cost=0.200108990
2016-11-28 10:34:40,204 - DEBUG - Accuracy(training batch): 87.50%
2016-11-28 10:35:39,894 - DEBUG - Epoch:   176;  cost=0.233064845
2016-11-28 10:35:39,907 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 10:36:39,667 - DEBUG - Epoch:   177;  cost=0.145146877
2016-11-28 10:36:39,680 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 10:37:39,725 - DEBUG - Epoch:   178;  cost=0.571374059
2016-11-28 10:37:39,737 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 10:38:39,529 - DEBUG - Epoch:   179;  cost=0.502275348
2016-11-28 10:38:39,541 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 10:39:39,163 - DEBUG - Epoch:   180;  cost=0.194519252
2016-11-28 10:39:39,175 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 10:40:39,802 - DEBUG - Epoch:   181;  cost=0.272240013
2016-11-28 10:40:39,814 - DEBUG - Accuracy(training batch): 98.44%
2016-11-28 10:40:58,023 - INFO - ***Accuracy - Full Training:         90.58%
2016-11-28 10:41:02,631 - INFO - ***Accuracy - Full Validation:       88.68%
2016-11-28 10:41:05,148 - INFO - ***Accuracy - Full Test:             79.76%
2016-11-28 10:42:05,018 - DEBUG - Epoch:   182;  cost=0.046572685
2016-11-28 10:42:05,035 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 10:43:04,955 - DEBUG - Epoch:   183;  cost=0.191237032
2016-11-28 10:43:04,968 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 10:44:04,609 - DEBUG - Epoch:   184;  cost=0.753117681
2016-11-28 10:44:04,622 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 10:45:04,315 - DEBUG - Epoch:   185;  cost=0.248578981
2016-11-28 10:45:04,328 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 10:46:04,161 - DEBUG - Epoch:   186;  cost=0.419393301
2016-11-28 10:46:04,174 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 10:47:03,899 - DEBUG - Epoch:   187;  cost=0.347407341
2016-11-28 10:47:03,911 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 10:48:03,836 - DEBUG - Epoch:   188;  cost=0.226576596
2016-11-28 10:48:03,848 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 10:49:03,742 - DEBUG - Epoch:   189;  cost=0.190136552
2016-11-28 10:49:03,754 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 10:50:03,404 - DEBUG - Epoch:   190;  cost=0.124795884
2016-11-28 10:50:03,417 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 10:51:03,347 - DEBUG - Epoch:   191;  cost=0.252933353
2016-11-28 10:51:03,360 - DEBUG - Accuracy(training batch): 96.88%
2016-11-28 10:51:21,507 - INFO - ***Accuracy - Full Training:         93.77%
2016-11-28 10:51:26,107 - INFO - ***Accuracy - Full Validation:       91.32%
2016-11-28 10:51:28,597 - INFO - ***Accuracy - Full Test:             80.71%
2016-11-28 10:52:28,752 - DEBUG - Epoch:   192;  cost=0.120027229
2016-11-28 10:52:28,764 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 10:53:28,796 - DEBUG - Epoch:   193;  cost=0.204111680
2016-11-28 10:53:28,809 - DEBUG - Accuracy(training batch): 98.44%
2016-11-28 10:54:28,862 - DEBUG - Epoch:   194;  cost=0.242081493
2016-11-28 10:54:28,875 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 10:55:29,069 - DEBUG - Epoch:   195;  cost=0.173736185
2016-11-28 10:55:29,081 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 10:56:29,078 - DEBUG - Epoch:   196;  cost=0.186136156
2016-11-28 10:56:29,091 - DEBUG - Accuracy(training batch): 98.44%
2016-11-28 10:57:28,995 - DEBUG - Epoch:   197;  cost=0.097653478
2016-11-28 10:57:29,008 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 10:58:28,873 - DEBUG - Epoch:   198;  cost=0.395792127
2016-11-28 10:58:28,886 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 10:59:28,876 - DEBUG - Epoch:   199;  cost=0.134131610
2016-11-28 10:59:28,889 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 11:00:28,867 - DEBUG - Epoch:   200;  cost=0.257486790
2016-11-28 11:00:28,880 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 11:00:28,880 - INFO - Optimization Finished!
2016-11-28 11:00:47,069 - INFO - ***Accuracy - Full Training:         93.12%
2016-11-28 11:00:51,666 - INFO - ***Accuracy - Full Validation:       90.54%
2016-11-28 11:00:54,182 - INFO - ***Accuracy - Full Test:             80.23%
2016-11-28 11:00:54,238 - INFO - Time usage: 3:24:27
2016-11-28 20:47:01,590 - DEBUG - Epoch:     1;  cost=1.682891130
2016-11-28 20:52:57,276 - DEBUG - Epoch:     1;  cost=0.917954087
2016-11-28 20:52:57,552 - DEBUG - Accuracy(training batch): 67.19%
2016-11-28 20:53:18,955 - INFO - ***Accuracy - Full Training:         71.24%
2016-11-28 20:53:24,836 - INFO - ***Accuracy - Full Validation:       70.02%
2016-11-28 20:53:27,967 - INFO - ***Accuracy - Full Test:             53.57%
2016-11-28 20:54:37,330 - DEBUG - Epoch:     2;  cost=0.564816415
2016-11-28 20:54:37,350 - DEBUG - Accuracy(training batch): 82.81%
2016-11-28 20:55:49,471 - DEBUG - Epoch:     3;  cost=0.636704206
2016-11-28 20:55:49,486 - DEBUG - Accuracy(training batch): 79.69%
2016-11-28 20:56:55,879 - DEBUG - Epoch:     4;  cost=0.474205554
2016-11-28 20:56:55,892 - DEBUG - Accuracy(training batch): 85.94%
2016-11-28 20:57:57,242 - DEBUG - Epoch:     5;  cost=0.435496569
2016-11-28 20:57:57,257 - DEBUG - Accuracy(training batch): 81.25%
2016-11-28 20:59:09,546 - DEBUG - Epoch:     6;  cost=0.241328686
2016-11-28 20:59:09,560 - DEBUG - Accuracy(training batch): 87.50%
2016-11-28 21:00:20,769 - DEBUG - Epoch:     7;  cost=0.603242397
2016-11-28 21:00:20,782 - DEBUG - Accuracy(training batch): 81.25%
2016-11-28 21:01:23,727 - DEBUG - Epoch:     8;  cost=0.336123228
2016-11-28 21:01:23,746 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 21:02:30,817 - DEBUG - Epoch:     9;  cost=0.428933948
2016-11-28 21:02:30,832 - DEBUG - Accuracy(training batch): 85.94%
2016-11-28 21:03:35,891 - DEBUG - Epoch:    10;  cost=0.330388308
2016-11-28 21:03:35,906 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 21:04:45,734 - DEBUG - Epoch:    11;  cost=0.157001361
2016-11-28 21:04:45,747 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 21:05:05,188 - INFO - ***Accuracy - Full Training:         90.55%
2016-11-28 21:05:10,492 - INFO - ***Accuracy - Full Validation:       89.00%
2016-11-28 21:05:13,166 - INFO - ***Accuracy - Full Test:             77.85%
2016-11-28 21:06:19,730 - DEBUG - Epoch:    12;  cost=0.387606472
2016-11-28 21:06:19,743 - DEBUG - Accuracy(training batch): 85.94%
2016-11-28 21:07:33,995 - DEBUG - Epoch:    13;  cost=0.177815497
2016-11-28 21:07:34,071 - DEBUG - Accuracy(training batch): 90.62%
2016-11-28 21:08:47,251 - DEBUG - Epoch:    14;  cost=0.283498347
2016-11-28 21:08:47,264 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 21:09:50,845 - DEBUG - Epoch:    15;  cost=0.477717847
2016-11-28 21:09:50,858 - DEBUG - Accuracy(training batch): 92.19%
2016-11-28 21:11:03,757 - DEBUG - Epoch:    16;  cost=0.360149384
2016-11-28 21:11:03,771 - DEBUG - Accuracy(training batch): 89.06%
2016-11-28 21:12:07,599 - DEBUG - Epoch:    17;  cost=0.320521116
2016-11-28 21:12:07,616 - DEBUG - Accuracy(training batch): 87.50%
2016-11-28 21:13:13,736 - DEBUG - Epoch:    18;  cost=0.157597631
2016-11-28 21:13:13,749 - DEBUG - Accuracy(training batch): 95.31%
2016-11-28 21:14:13,563 - DEBUG - Epoch:    19;  cost=0.234199345
2016-11-28 21:14:13,576 - DEBUG - Accuracy(training batch): 93.75%
2016-11-28 21:38:29,235 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-28 21:38:29,337 - INFO - Learning Rate: 0.001
2016-11-28 21:38:29,338 - INFO - Batch Size: 64
2016-11-28 21:38:29,338 - INFO - Kernal Size: 5 x 5
2016-11-28 21:38:29,382 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-28 21:38:29,382 - INFO - Dropout keep_prob: 0.8
2016-11-28 21:38:29,383 - INFO - layer_convn1: Tensor("Relu:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-28 21:38:29,383 - INFO - layer_convn2: Tensor("Relu_1:0", shape=(?, 8, 8, 32), dtype=float32)
2016-11-28 21:38:29,383 - INFO - layer_fc1: Tensor("dropout/mul:0", shape=(?, 128), dtype=float32)
2016-11-28 21:38:29,383 - INFO - logits: Tensor("Add_3:0", shape=(?, 43), dtype=float32)
2016-11-28 21:44:52,779 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-28 21:44:52,939 - INFO - Learning Rate: 0.001
2016-11-28 21:44:52,939 - INFO - Batch Size: 64
2016-11-28 21:44:52,939 - INFO - Kernal Size: 5 x 5
2016-11-28 21:44:52,940 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-28 21:44:52,940 - INFO - Dropout keep_prob: 0.8
2016-11-28 21:44:52,940 - INFO - layer_convn1: Tensor("Relu_3:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-28 21:44:52,940 - INFO - layer_convn2: Tensor("Relu_4:0", shape=(?, 8, 8, 32), dtype=float32)
2016-11-28 21:44:52,940 - INFO - layer_fc1: Tensor("dropout_1/mul:0", shape=(?, 128), dtype=float32)
2016-11-28 21:44:52,941 - INFO - logits: Tensor("Add_7:0", shape=(?, 43), dtype=float32)
2016-11-28 21:46:16,684 - DEBUG - Epoch:     1;  cost=1.523004055
2016-11-28 21:46:16,724 - DEBUG - Accuracy(training batch): 43.75%
2016-11-28 21:46:37,327 - INFO - ***Accuracy - Full Training:         48.42%
2016-11-28 21:46:43,189 - INFO - ***Accuracy - Full Validation:       48.47%
2016-11-28 21:46:45,707 - INFO - ***Accuracy - Full Test:             37.64%
2016-11-28 21:47:48,391 - DEBUG - Epoch:     2;  cost=1.076288700
2016-11-28 21:47:48,403 - DEBUG - Accuracy(training batch): 70.31%
2016-11-28 21:48:48,766 - DEBUG - Epoch:     3;  cost=0.603858709
2016-11-28 21:48:48,779 - DEBUG - Accuracy(training batch): 73.44%
2016-11-28 21:49:55,278 - DEBUG - Epoch:     4;  cost=0.717818379
2016-11-28 21:49:55,291 - DEBUG - Accuracy(training batch): 85.94%
2016-11-28 21:51:01,343 - DEBUG - Epoch:     5;  cost=0.499370277
2016-11-28 21:51:01,373 - DEBUG - Accuracy(training batch): 79.69%
2016-11-28 21:51:01,374 - INFO - Optimization Finished!
2016-11-28 21:51:25,063 - INFO - ***Accuracy - Full Training:         82.44%
2016-11-28 21:51:30,049 - INFO - ***Accuracy - Full Validation:       81.12%
2016-11-28 21:51:32,943 - INFO - ***Accuracy - Full Test:             68.72%
2016-11-28 21:51:32,944 - INFO - Time usage: 0:06:17
2016-11-28 23:44:25,430 - INFO - ========================================
                                     Training Begins - AdamOptimizer  
=========================================================================
2016-11-28 23:44:25,430 - INFO - Learning Rate: 0.001
2016-11-28 23:44:25,431 - INFO - Batch Size: 64
2016-11-28 23:44:25,431 - INFO - Kernal Size: 5 x 5
2016-11-28 23:44:25,434 - INFO - Stride Parameters Size: [1, 2, 2, 1]
2016-11-28 23:44:25,434 - INFO - Dropout keep_prob: 0.8
2016-11-28 23:44:25,435 - INFO - layer_convn1: Tensor("Relu:0", shape=(?, 16, 16, 16), dtype=float32)
2016-11-28 23:44:25,435 - INFO - layer_convn2: Tensor("Relu_1:0", shape=(?, 8, 8, 32), dtype=float32)
2016-11-28 23:44:25,435 - INFO - layer_fc1: Tensor("dropout/mul:0", shape=(?, 128), dtype=float32)
2016-11-28 23:44:25,435 - INFO - logits: Tensor("Add_3:0", shape=(?, 43), dtype=float32)
2016-11-28 23:45:23,498 - DEBUG - Epoch:     1;  cost=1.446886420
2016-11-28 23:45:23,525 - DEBUG - Accuracy(training batch): 40.62%
2016-11-28 23:45:43,850 - INFO - ***Accuracy - Full Training:         52.41%
2016-11-28 23:45:48,722 - INFO - ***Accuracy - Full Validation:       52.22%
2016-11-28 23:45:51,267 - INFO - ***Accuracy - Full Test:             39.93%
2016-11-28 23:46:47,975 - DEBUG - Epoch:     2;  cost=0.863580823
2016-11-28 23:46:47,991 - DEBUG - Accuracy(training batch): 57.81%
2016-11-28 23:47:47,416 - DEBUG - Epoch:     3;  cost=0.817820072
2016-11-28 23:47:47,443 - DEBUG - Accuracy(training batch): 79.69%
2016-11-28 23:48:46,178 - DEBUG - Epoch:     4;  cost=0.739009380
2016-11-28 23:48:46,191 - DEBUG - Accuracy(training batch): 79.69%
2016-11-28 23:49:45,779 - DEBUG - Epoch:     5;  cost=0.538548350
2016-11-28 23:49:45,793 - DEBUG - Accuracy(training batch): 82.81%
2016-11-28 23:49:45,794 - INFO - Optimization Finished!
2016-11-28 23:50:05,247 - INFO - ***Accuracy - Full Training:         82.02%
2016-11-28 23:50:10,524 - INFO - ***Accuracy - Full Validation:       80.38%
2016-11-28 23:50:13,148 - INFO - ***Accuracy - Full Test:             65.40%
2016-11-28 23:50:13,148 - INFO - Time usage: 0:05:47
